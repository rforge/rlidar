{
    "contents" : "detach(spp)\nrm(list=ls())\nspp=read.csv(\"SPP_BA_TD_data.csv\",header=TRUE,row.names=1,as.is=TRUE)\nattach(spp)\n\n# I needed to remove nonsense variables that were in polar coordinates (ASP), were solely a function of\n# sampling density (N, VEGN, GNDN), or were too highly correlated to other variables.  Jeff changed the\n# total % vegetation field to only include returns >1 m, so this field is no longer perfectly inversely\n# correlated with STRATUM0, the percentage of ground returns.  Since the ALI variables were proving no\n# help, I also eliminated them from the analyis to simplify things.\n\ny=spp[,1:36]\nx=spp[,37:100]  # The ALI variables are not helping really so I will not include them in the analysis.\n\nbag=c(\"ASP\",\"N\",\"VEGN\",\"GNDN\")\nkeep=setdiff(colnames(x),bag)\nx=x[,keep]                     # Omit unwanted x's from consideration.\n\n# Order the BA and TD data.\nfor (i in 1:17)\n  print(c(names(y[i]),sum(y[,i])))\nfor (i in 19:35)\n  print(c(names(y[i]),sum(y[,i])))\n\ncone=c(\"PIPO_BA\",\"PSME_BA\",\"LAOC_BA\",\"PICO_BA\",\"ABGR_BA\",\"PIMO_BA\",\"THPL_BA\",\"TSHE_BA\",\n       \"PIEN_BA\",\"ABLA_BA\",\"TSME_BA\",\"PIPO_TD\",\"PSME_TD\",\"LAOC_TD\",\"PICO_TD\",\"ABGR_TD\",\"PIMO_TD\",\n       \"THPL_TD\",\"TSHE_TD\",\"PIEN_TD\",\"ABLA_TD\",\"TSME_TD\")\n\nmost=c(\"PSME_BA\",\"LAOC_BA\",\"ABGR_BA\",\"THPL_BA\",\"PSME_TD\",\"LAOC_TD\",\"ABGR_TD\",\"THPL_TD\")\n\n# Nick's boil function to transform y data object is now \"whatsMax\"\nbasp=y[,1:17]\ntdsp=y[,19:35]\nrequire(yaImpute)\nspba=whatsMax(basp)\nsptd=whatsMax(tdsp)\nrfy=cbind(spba,sptd)\n\n# I need to explore whether I should apply yai to all y's, just the 22 conifer variables,\n# just the 8 y's that are most prevalent, or just the what's maximum y's.  Then I will\n# test which yai object is best for imputation.\n\nk=1\nrf.test = yai(x=x, y=rfy, method=\"randomForest\", k=k, ann=F, ntree=300*ncol(rfy))\n# rf.test$ranForest$basp.maxCol  # Look at the OOB estimate of error rate\n# 50 trees = error rate of 70.62%\n# 250 trees = error rate of 62.8%\n# 300 trees = error rate of <60%\n# 350 trees = error rate of 65.85%\n# 500 trees = error rate of 62.58%\n# Looks like I do best with about 300 classification trees.\n\nrf.60.all = yai(x=x, y=y, method=\"randomForest\", k=k, ann=F, ntree=300*ncol(y))\nrf.60.cone = yai(x=x, y=y[,cone], method=\"randomForest\", k=k, ann=F, ntree=300*length(cone))\nrf.60.most = yai(x=x, y=y[,most], method=\"randomForest\", k=k, ann=F, ntree=300*length(most))\nrf.60.wmax = yai(x=x, y=rfy, method=\"randomForest\", k=k, ann=F, ntree=300*ncol(rfy))\nopar <- par(mfrow=c(2,2))\nrf.60.all.rmsd=rmsd.yai(impute.yai(rf.60.all,newdata=y,method=\"closest\",observed=TRUE),scale=T)\nrf.60.cone.rmsd=rmsd.yai(impute.yai(rf.60.cone,newdata=y,method=\"closest\",observed=TRUE),scale=T)\nrf.60.most.rmsd=rmsd.yai(impute.yai(rf.60.most,newdata=y,method=\"closest\",observed=TRUE),scale=T)\nrf.60.wmax.rmsd=rmsd.yai(impute.yai(rf.60.wmax,newdata=y,method=\"closest\",observed=TRUE),scale=T)\nrf.60.rmsd=cbind(rf.60.all.rmsd,rf.60.cone.rmsd,rf.60.most.rmsd,rf.60.wmax.rmsd)\ncolnames(rf.60.rmsd)=c(\"ALL\",\"CONE\",\"MOST\",\"WMAX\")\nboxplot(rf.60.rmsd, notch=TRUE, main=\"Impute all 36 Y variables\", xlab=\"YAI Object\", ylab=\"RMSD\", cex.axis=0.8)\nsummary(rf.60.rmsd)\n\nrf.60.all.rmsd=rmsd.yai(impute.yai(rf.60.all,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.60.cone.rmsd=rmsd.yai(impute.yai(rf.60.cone,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.60.most.rmsd=rmsd.yai(impute.yai(rf.60.most,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.60.wmax.rmsd=rmsd.yai(impute.yai(rf.60.wmax,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.60.rmsd=cbind(rf.60.all.rmsd,rf.60.cone.rmsd,rf.60.most.rmsd,rf.60.wmax.rmsd)\ncolnames(rf.60.rmsd)=c(\"ALL\",\"CONE\",\"MOST\",\"WMAX\")\nboxplot(rf.60.rmsd, notch=TRUE, main=\"Impute Top 22 Ys (11 Conifers)\", xlab=\"YAI Object\", ylab=\"RMSD\", cex.axis=0.8)\nsummary(rf.60.rmsd)\n\nrf.60.all.rmsd=rmsd.yai(impute.yai(rf.60.all,newdata=y[,most],method=\"closest\",observed=TRUE),scale=T)\nrf.60.cone.rmsd=rmsd.yai(impute.yai(rf.60.cone,newdata=y[,most],method=\"closest\",observed=TRUE),scale=T)\nrf.60.most.rmsd=rmsd.yai(impute.yai(rf.60.most,newdata=y[,most],method=\"closest\",observed=TRUE),scale=T)\nrf.60.wmax.rmsd=rmsd.yai(impute.yai(rf.60.wmax,newdata=y[,most],method=\"closest\",observed=TRUE),scale=T)\nrf.60.rmsd=cbind(rf.60.all.rmsd,rf.60.cone.rmsd,rf.60.most.rmsd,rf.60.wmax.rmsd)\ncolnames(rf.60.rmsd)=c(\"ALL\",\"CONE\",\"MOST\",\"WMAX\")\nboxplot(rf.60.rmsd, notch=TRUE, main=\"Impute Top 8 Ys (4 Prevalent Conifers)\", xlab=\"YAI Object\", ylab=\"RMSD\", cex.axis=0.8)\nsummary(rf.60.rmsd)\n\nrf.60.all.rmsd=rmsd.yai(impute.yai(rf.60.all,newdata=rfy,method=\"closest\",observed=TRUE),scale=T)\nrf.60.cone.rmsd=rmsd.yai(impute.yai(rf.60.cone,newdata=rfy,method=\"closest\",observed=TRUE),scale=T)\nrf.60.most.rmsd=rmsd.yai(impute.yai(rf.60.most,newdata=rfy,method=\"closest\",observed=TRUE),scale=T)\nrf.60.wmax.rmsd=rmsd.yai(impute.yai(rf.60.wmax,newdata=rfy,method=\"closest\",observed=TRUE),scale=T)\nrf.60.rmsd=cbind(rf.60.all.rmsd,rf.60.cone.rmsd,rf.60.most.rmsd,rf.60.wmax.rmsd)\ncolnames(rf.60.rmsd)=c(\"ALL\",\"CONE\",\"MOST\",\"WMAX\")\nboxplot(rf.60.rmsd, notch=TRUE, main=\"Impute What's Max Ys\", xlab=\"YAI Object\", ylab=\"RMSD\", cex.axis=0.8)\nsummary(rf.60.rmsd)\npar(opar)\n\n# Based on this analysis, the WMAX yai object produces the lowest RMSDs overall.\n\n# Function Nick wrote to boxplot range of Gini index values.  Nick included the\n# funciton \"yaiVarImp\" in the package that sorts on the median value, but I want\n# to sort on the mean.\n\nyaVarImp = function(rf, nTop=20)\n{\n  if (class(rf) != \"yai\") stop (\"arg must be of class yai\")\n  allImp = matrix(0, nrow=length(names(rf$ranForest)), ncol=length(xvars(rf)))\n  colnames(allImp) = xvars(rf)\n  rownames(allImp) = names(rf$ranForest)\n  \n  i = 0\n  for (rfObj in rf$ranForest)\n  {\n    i = i+1\n    allImp[i,] = importance(rfObj)[,\"MeanDecreaseGini\"]\n  }\n  \n  allImp = data.frame(allImp)\n  nTop = min(ncol(allImp), nTop)\n  plt = par()$plt\n  oldplt = plt\n  plt[1] = .2\n  best = sort(apply(allImp, 2, mean), decreasing = TRUE, index.return = TRUE)$ix[1:nTop]\n  boxplot(as.data.frame(allImp[,best]), horizontal=TRUE, par(plt=plt), las=1,\n          main=deparse(substitute(rf)), xlab=\"MeanDecreaseGini\")\n  par(plt=oldplt)\n  invisible(list(allImp=allImp, best=best))\n}\n\n\n# Prune x variables in a simulated stepwise procedure, based on WMAX yai object.  I'm also\n# simulating a best subsets procedure, because I'm running random forest at each step,\n# or for an ordered number of subset variables.\nsink(\"xvars.test_4.txt\")\npred = x\nfor (j in 1:100) {\n  for (i in 2:length(pred)) {  # Use at least 6 variables, based on preliminary results\n    rf.test = yai(x=pred, y=rfy, method=\"randomForest\", k=k, ann=F, ntree=300*ncol(rfy))\n    yaVarImp(rf.test, nTop=length(pred))  # If I use \"yaiVarImp\" instead, it will sort by medians\n    v1 = importance(rf.test$ranForest[[1]])[,\"MeanDecreaseGini\"]\n    v2 = importance(rf.test$ranForest[[2]])[,\"MeanDecreaseGini\"]\n    v3 = importance(rf.test$ranForest[[3]])[,\"MeanDecreaseGini\"]\n    v4 = importance(rf.test$ranForest[[4]])[,\"MeanDecreaseGini\"]\n    vmean = (v1+v2+v3+v4)/ncol(rfy)\n    vsort = sort(vmean, decreasing=T)\n    rf.test.rmsd = rmsd.yai(impute(rf.test,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\n    keep = names(vsort[1:length(vsort)-1])\n    if (mean(rf.test.rmsd) < 0.45) {\n      cat(length(pred),names(vsort[1:length(vsort)]), \"\\n\")\n      cat(length(pred),mean(rf.test.rmsd), \"\\n\")\n    } else {\n      pred = x[,keep]\n    }\n    pred = x[,keep]\n  }\n  pred = x\n}\nsink()\n\n# I tested what were promising x variables just to be sure; here's a subset of 15 x variables.\nx=spp[,37:100]\nkeep = c(\"DENSITY\",\"HAAD\",\"H25TH\",\"PCT2\",\"ELEV\",\"HRANGE\",\"ISKEW\",\"STRATUM1\",\"HCV\",\"TSRAI\",\"H05TH\",\n         \"IIQR\",\"STRATUM4\",\"STRATUM0\",\"IVAR\",\"STRATUM2\")\nx = x[,keep]\n\n# Eleven variables from the above subset of 15 produced relatively good models with low mean RMSD:\nx = spp[,37:100]\nkeep = c(\"STRATUM1\",\"IVAR\",\"HCV\",\"H05TH\",\"HAAD\",\"ISKEW\",\"HRANGE\",\"H25TH\",\"ELEV\",\"PCT2\",\"DENSITY\")\nx = x[,keep]\n\n# After so many runs, I added TSRAI to the above 11 good predictor variables, which I wanted to include\n# because it integrated slope and aspect effects, which we know are important, much like I justified\n# including northing and easting in the CJRS regression paper analysis.\nx=spp[,37:100]\nkeep = c(\"TSRAI\",\"STRATUM1\",\"IVAR\",\"HCV\",\"H05TH\",\"HAAD\",\"ISKEW\",\"HRANGE\",\"H25TH\",\"ELEV\",\"PCT2\",\"DENSITY\")\nx = x[,keep]\n\n# I did many runs exploring different variable combinations, recorded in earlier log files and spreadsheets.\n# HVAR and HAAD were good variables but highly correlated (>0.95).  HAAD was more often being selected highly,\n# but I compared 12-variable model runs with HVAR, and without, to see which produced lower mean RMSD models.\n# First, I tried 100 reps of 12-variable models with HVAR\nx=spp[,37:100]\nkeep = c(\"TSRAI\",\"STRATUM1\",\"IVAR\",\"HVAR\",\"HCV\",\"H05TH\",\"ISKEW\",\"HRANGE\",\"H25TH\",\"ELEV\",\"PCT2\",\"DENSITY\")\nx = x[,keep]\nsink(\"xvars.test_HVAR.txt\")\npred = x\nfor (j in 1:100) {\n  for (i in 12:length(pred)) {  # Use at least 6 variables, based on preliminary results\n    rf.test = yai(x=pred, y=rfy, method=\"randomForest\", k=k, ann=F, ntree=300*ncol(rfy))\n    yaVarImp(rf.test, nTop=length(pred))  # If I use \"yaiVarImp\" instead, it will sort by medians\n    v1 = importance(rf.test$ranForest[[1]])[,\"MeanDecreaseGini\"]\n    v2 = importance(rf.test$ranForest[[2]])[,\"MeanDecreaseGini\"]\n    v3 = importance(rf.test$ranForest[[3]])[,\"MeanDecreaseGini\"]\n    v4 = importance(rf.test$ranForest[[4]])[,\"MeanDecreaseGini\"]\n    vmean = (v1+v2+v3+v4)/ncol(rfy)\n    vsort = sort(vmean, decreasing=T)\n    rf.test.rmsd = rmsd.yai(impute(rf.test,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\n    keep = names(vsort[1:length(vsort)-1])\n    # if (mean(rf.test.rmsd) < 0.45) {\n    cat(length(pred),names(vsort[1:length(vsort)]), \"\\n\")\n    cat(length(pred),mean(rf.test.rmsd), \"\\n\")\n    # } else {\n    # pred = x[,keep]\n    # }\n    pred = x[,keep]\n  }\n  pred = x\n}\nsink()\n\n# Then I tried 100 reps of 12-variable models with HAAD\nx=spp[,37:100]\nkeep = c(\"TSRAI\",\"STRATUM1\",\"IVAR\",\"HCV\",\"H05TH\",\"HAAD\",\"ISKEW\",\"HRANGE\",\"H25TH\",\"ELEV\",\"PCT2\",\"DENSITY\")\nx = x[,keep]\nsink(\"xvars.test_HAAD.txt\")\npred = x\nfor (j in 1:100) {\n  for (i in 12:length(pred)) {  # Use at least 6 variables, based on preliminary results\n    rf.test = yai(x=pred, y=rfy, method=\"randomForest\", k=k, ann=F, ntree=300*ncol(rfy))\n    yaVarImp(rf.test, nTop=length(pred))  # If I use \"yaiVarImp\" instead, it will sort by medians\n    v1 = importance(rf.test$ranForest[[1]])[,\"MeanDecreaseGini\"]\n    v2 = importance(rf.test$ranForest[[2]])[,\"MeanDecreaseGini\"]\n    v3 = importance(rf.test$ranForest[[3]])[,\"MeanDecreaseGini\"]\n    v4 = importance(rf.test$ranForest[[4]])[,\"MeanDecreaseGini\"]\n    vmean = (v1+v2+v3+v4)/ncol(rfy)\n    vsort = sort(vmean, decreasing=T)\n    rf.test.rmsd = rmsd.yai(impute(rf.test,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\n    keep = names(vsort[1:length(vsort)-1])\n    # if (mean(rf.test.rmsd) < 0.45) {\n    cat(length(pred),names(vsort[1:length(vsort)]), \"\\n\")\n    cat(length(pred),mean(rf.test.rmsd), \"\\n\")\n    # } else {\n    # pred = x[,keep]\n    # }\n    pred = x[,keep]\n  }\n  pred = x\n}\nsink()\n\n# The 12-variable subset with HAAD had a lower mean RMSD over 100 reps, 0.645 compared to 0.708 with HVAR.\n# Interestingly, neither subset produced any models with mean RMSD <0.45.  They are very stable.  That is\n# probably because I was careful to eliminate X variables too highly correlated with each other.\n# So, I will use the following 12 X variables:\nx = spp[,37:100]\nkeep = c(\"TSRAI\",\"STRATUM1\",\"IVAR\",\"HCV\",\"H05TH\",\"HAAD\",\"ISKEW\",\"HRANGE\",\"H25TH\",\"ELEV\",\"PCT2\",\"DENSITY\")\nx = x[,keep]\n\n# Let's compare the above to a minimalist subset of 4 X variables:\nx=spp[,37:100]\nkeep=c(\"DENSITY\",\"PCT2\",\"H25TH\",\"ELEV\")\nx = x[,keep]\nsink(\"xvars.test_4xvars.txt\")\npred = x\nfor (j in 1:100) {\n  for (i in 4:length(pred)) {  # Use at least 6 variables, based on preliminary results\n    rf.test = yai(x=pred, y=rfy, method=\"randomForest\", k=k, ann=F, ntree=300*ncol(rfy))\n    yaVarImp(rf.test, nTop=length(pred))  # If I use \"yaiVarImp\" instead, it will sort by medians\n    v1 = importance(rf.test$ranForest[[1]])[,\"MeanDecreaseGini\"]\n    v2 = importance(rf.test$ranForest[[2]])[,\"MeanDecreaseGini\"]\n    v3 = importance(rf.test$ranForest[[3]])[,\"MeanDecreaseGini\"]\n    v4 = importance(rf.test$ranForest[[4]])[,\"MeanDecreaseGini\"]\n    vmean = (v1+v2+v3+v4)/ncol(rfy)\n    vsort = sort(vmean, decreasing=T)\n    rf.test.rmsd = rmsd.yai(impute(rf.test,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\n    keep = names(vsort[1:length(vsort)-1])\n    # if (mean(rf.test.rmsd) < 0.45) {\n    cat(length(pred),names(vsort[1:length(vsort)]), \"\\n\")\n    cat(length(pred),mean(rf.test.rmsd), \"\\n\")\n    # } else {\n    # pred = x[,keep]\n    # }\n    pred = x[,keep]\n  }\n  pred = x\n}\nsink()\n\n# The mean RMSD after 100 reps is 0.635, which is better.  What if I use HRANGE instead of ELEV?\n# The following model produced 0.276, the lowest RMSD of the many test runs I've done in the past month.\nx=spp[,37:100]\nkeep=c(\"DENSITY\",\"PCT2\",\"H25TH\",\"HRANGE\")\nx = x[,keep]\nsink(\"xvars.test_4best.txt\")\npred = x\nfor (j in 1:100) {\n  for (i in 4:length(pred)) {  # Use at least 6 variables, based on preliminary results\n    rf.test = yai(x=pred, y=rfy, method=\"randomForest\", k=k, ann=F, ntree=300*ncol(rfy))\n    yaVarImp(rf.test, nTop=length(pred))  # If I use \"yaiVarImp\" instead, it will sort by medians\n    v1 = importance(rf.test$ranForest[[1]])[,\"MeanDecreaseGini\"]\n    v2 = importance(rf.test$ranForest[[2]])[,\"MeanDecreaseGini\"]\n    v3 = importance(rf.test$ranForest[[3]])[,\"MeanDecreaseGini\"]\n    v4 = importance(rf.test$ranForest[[4]])[,\"MeanDecreaseGini\"]\n    vmean = (v1+v2+v3+v4)/ncol(rfy)\n    vsort = sort(vmean, decreasing=T)\n    rf.test.rmsd = rmsd.yai(impute(rf.test,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\n    keep = names(vsort[1:length(vsort)-1])\n    # if (mean(rf.test.rmsd) < 0.45) {\n    cat(length(pred),names(vsort[1:length(vsort)]), \"\\n\")\n    cat(length(pred),mean(rf.test.rmsd), \"\\n\")\n    # } else {\n    # pred = x[,keep]\n    # }\n    pred = x[,keep]\n  }\n  pred = x\n}\nsink()\n\n# Wow!  This mean RMSD was 0.414 over 100 reps, which blows away the other models.\n# Another seemingly good model was 3 variables remaining if PCT2 is dropped, so I tried it.\nx=spp[,37:100]\nkeep=c(\"DENSITY\",\"H25TH\",\"HRANGE\")\nx = x[,keep]\nsink(\"xvars.test_3best.txt\")\npred = x\nfor (j in 1:100) {\n  for (i in 3:length(pred)) {  # Use at least 6 variables, based on preliminary results\n    rf.test = yai(x=pred, y=rfy, method=\"randomForest\", k=k, ann=F, ntree=300*ncol(rfy))\n    yaVarImp(rf.test, nTop=length(pred))  # If I use \"yaiVarImp\" instead, it will sort by medians\n    v1 = importance(rf.test$ranForest[[1]])[,\"MeanDecreaseGini\"]\n    v2 = importance(rf.test$ranForest[[2]])[,\"MeanDecreaseGini\"]\n    v3 = importance(rf.test$ranForest[[3]])[,\"MeanDecreaseGini\"]\n    v4 = importance(rf.test$ranForest[[4]])[,\"MeanDecreaseGini\"]\n    vmean = (v1+v2+v3+v4)/ncol(rfy)\n    vsort = sort(vmean, decreasing=T)\n    rf.test.rmsd = rmsd.yai(impute(rf.test,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\n    keep = names(vsort[1:length(vsort)-1])\n    # if (mean(rf.test.rmsd) < 0.45) {\n    cat(length(pred),names(vsort[1:length(vsort)]), \"\\n\")\n    cat(length(pred),mean(rf.test.rmsd), \"\\n\")\n    # } else {\n    # pred = x[,keep]\n    # }\n    pred = x[,keep]\n  }\n  pred = x\n}\nsink()\n\n# Here, the mean RMSD after 100 reps was 0.572.  So the former 4-variable subset was the winner.\n\n## So, I can compare boxplots using all 60 x variables (above) to 12 or 4 x variables.\nx = spp[,37:100]\nkeep = c(\"ELEV\",\"TSRAI\",\"HRANGE\",\"HAAD\",\"HCV\",\"H05TH\",\"H25TH\",\"IVAR\",\"ISKEW\",\"DENSITY\",\"STRATUM1\",\"PCT2\")\npred = x[,keep]\nrf.all = yai(x=pred, y=y, method=\"randomForest\", k=k, ann=F, ntree=300*ncol(y))\nrf.cone = yai(x=pred, y=y[,cone], method=\"randomForest\", k=k, ann=F, ntree=300*length(cone))\nrf.most = yai(x=pred, y=y[,most], method=\"randomForest\", k=k, ann=F, ntree=300*length(most))\nrf.wmax = yai(x=pred, y=rfy, method=\"randomForest\", k=k, ann=F, ntree=300*ncol(rfy))\nopar <- par(mfrow=c(2,2))\nrf.all.rmsd=rmsd.yai(impute.yai(rf.all,newdata=y,method=\"closest\",observed=TRUE),scale=T)\nrf.cone.rmsd=rmsd.yai(impute.yai(rf.cone,newdata=y,method=\"closest\",observed=TRUE),scale=T)\nrf.most.rmsd=rmsd.yai(impute.yai(rf.most,newdata=y,method=\"closest\",observed=TRUE),scale=T)\nrf.wmax.rmsd=rmsd.yai(impute.yai(rf.wmax,newdata=y,method=\"closest\",observed=TRUE),scale=T)\nrf.rmsd=cbind(rf.all.rmsd,rf.cone.rmsd,rf.most.rmsd,rf.wmax.rmsd)\ncolnames(rf.rmsd)=c(\"ALL\",\"CONE\",\"MOST\",\"WMAX\")\nboxplot(rf.rmsd, notch=TRUE, main=\"Impute all 36 Y variables\", xlab=\"YAI Object\", ylab=\"RMSD\", cex.axis=0.8)\nsummary(rf.rmsd)\n\nrf.all.rmsd=rmsd.yai(impute.yai(rf.all,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.cone.rmsd=rmsd.yai(impute.yai(rf.cone,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.most.rmsd=rmsd.yai(impute.yai(rf.most,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.wmax.rmsd=rmsd.yai(impute.yai(rf.wmax,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.rmsd=cbind(rf.all.rmsd,rf.cone.rmsd,rf.most.rmsd,rf.wmax.rmsd)\ncolnames(rf.rmsd)=c(\"ALL\",\"CONE\",\"MOST\",\"WMAX\")\nboxplot(rf.rmsd, notch=TRUE, main=\"Impute Top 22 Ys (11 Conifers)\", xlab=\"YAI Object\", ylab=\"RMSD\", cex.axis=0.8)\nsummary(rf.rmsd)\n\nrf.all.rmsd=rmsd.yai(impute.yai(rf.all,newdata=y[,most],method=\"closest\",observed=TRUE),scale=T)\nrf.cone.rmsd=rmsd.yai(impute.yai(rf.cone,newdata=y[,most],method=\"closest\",observed=TRUE),scale=T)\nrf.most.rmsd=rmsd.yai(impute.yai(rf.most,newdata=y[,most],method=\"closest\",observed=TRUE),scale=T)\nrf.wmax.rmsd=rmsd.yai(impute.yai(rf.wmax,newdata=y[,most],method=\"closest\",observed=TRUE),scale=T)\nrf.rmsd=cbind(rf.all.rmsd,rf.cone.rmsd,rf.most.rmsd,rf.wmax.rmsd)\ncolnames(rf.rmsd)=c(\"ALL\",\"CONE\",\"MOST\",\"WMAX\")\nboxplot(rf.rmsd, notch=TRUE, main=\"Impute Top 8 Ys (4 Prevalent Conifers)\", xlab=\"YAI Object\", ylab=\"RMSD\", cex.axis=0.8)\nsummary(rf.rmsd)\n\nrf.all.rmsd=rmsd.yai(impute.yai(rf.all,newdata=rfy,method=\"closest\",observed=TRUE),scale=T)\nrf.cone.rmsd=rmsd.yai(impute.yai(rf.cone,newdata=rfy,method=\"closest\",observed=TRUE),scale=T)\nrf.most.rmsd=rmsd.yai(impute.yai(rf.most,newdata=rfy,method=\"closest\",observed=TRUE),scale=T)\nrf.wmax.rmsd=rmsd.yai(impute.yai(rf.wmax,newdata=rfy,method=\"closest\",observed=TRUE),scale=T)\nrf.rmsd=cbind(rf.all.rmsd,rf.cone.rmsd,rf.most.rmsd,rf.wmax.rmsd)\ncolnames(rf.rmsd)=c(\"ALL\",\"CONE\",\"MOST\",\"WMAX\")\nboxplot(rf.rmsd, notch=TRUE, main=\"Impute Max Species Ys\", xlab=\"YAI Object\", ylab=\"RMSD\", cex.axis=0.8)\nsummary(rf.rmsd)\npar(opar)\n\nx = spp[,37:100]\nkeep = c(\"HRANGE\",\"H25TH\",\"PCT2\",\"DENSITY\")\npred.4 = x[,keep]\nrf.4.all = yai(x=pred.4, y=y, method=\"randomForest\", k=k, ann=F, ntree=300*ncol(y))\nrf.4.cone = yai(x=pred.4, y=y[,cone], method=\"randomForest\", k=k, ann=F, ntree=300*length(cone))\nrf.4.most = yai(x=pred.4, y=y[,most], method=\"randomForest\", k=k, ann=F, ntree=300*length(most))\nrf.4.wmax = yai(x=pred.4, y=rfy, method=\"randomForest\", k=k, ann=F, ntree=300*ncol(rfy))\nopar <- par(mfrow=c(2,2))\nrf.4.all.rmsd=rmsd.yai(impute.yai(rf.4.all,newdata=y,method=\"closest\",observed=TRUE),scale=T)\nrf.4.cone.rmsd=rmsd.yai(impute.yai(rf.4.cone,newdata=y,method=\"closest\",observed=TRUE),scale=T)\nrf.4.most.rmsd=rmsd.yai(impute.yai(rf.4.most,newdata=y,method=\"closest\",observed=TRUE),scale=T)\nrf.4.wmax.rmsd=rmsd.yai(impute.yai(rf.4.wmax,newdata=y,method=\"closest\",observed=TRUE),scale=T)\nrf.4.rmsd=cbind(rf.4.all.rmsd,rf.4.cone.rmsd,rf.4.most.rmsd,rf.4.wmax.rmsd)\ncolnames(rf.4.rmsd)=c(\"ALL\",\"CONE\",\"MOST\",\"WMAX\")\nboxplot(rf.4.rmsd, notch=TRUE, main=\"Impute all 36 Y variables\", xlab=\"YAI Object\", ylab=\"RMSD\", cex.axis=0.8)\nsummary(rf.4.rmsd)\n\nrf.4.all.rmsd=rmsd.yai(impute.yai(rf.4.all,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.4.cone.rmsd=rmsd.yai(impute.yai(rf.4.cone,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.4.most.rmsd=rmsd.yai(impute.yai(rf.4.most,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.4.wmax.rmsd=rmsd.yai(impute.yai(rf.4.wmax,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.4.rmsd=cbind(rf.4.all.rmsd,rf.4.cone.rmsd,rf.4.most.rmsd,rf.4.wmax.rmsd)\ncolnames(rf.4.rmsd)=c(\"ALL\",\"CONE\",\"MOST\",\"WMAX\")\nboxplot(rf.4.rmsd, notch=TRUE, main=\"Impute Top 22 Ys (11 Conifers)\", xlab=\"YAI Object\", ylab=\"RMSD\", cex.axis=0.8)\nsummary(rf.4.rmsd)\n\nrf.4.all.rmsd=rmsd.yai(impute.yai(rf.4.all,newdata=y[,most],method=\"closest\",observed=TRUE),scale=T)\nrf.4.cone.rmsd=rmsd.yai(impute.yai(rf.4.cone,newdata=y[,most],method=\"closest\",observed=TRUE),scale=T)\nrf.4.most.rmsd=rmsd.yai(impute.yai(rf.4.most,newdata=y[,most],method=\"closest\",observed=TRUE),scale=T)\nrf.4.wmax.rmsd=rmsd.yai(impute.yai(rf.4.wmax,newdata=y[,most],method=\"closest\",observed=TRUE),scale=T)\nrf.4.rmsd=cbind(rf.4.all.rmsd,rf.4.cone.rmsd,rf.4.most.rmsd,rf.4.wmax.rmsd)\ncolnames(rf.4.rmsd)=c(\"ALL\",\"CONE\",\"MOST\",\"WMAX\")\nboxplot(rf.4.rmsd, notch=TRUE, main=\"Impute Top 8 Ys (4 Prevalent Conifers)\", xlab=\"YAI Object\", ylab=\"RMSD\", cex.axis=0.8)\nsummary(rf.4.rmsd)\n\nrf.4.all.rmsd=rmsd.yai(impute.yai(rf.4.all,newdata=rfy,method=\"closest\",observed=TRUE),scale=T)\nrf.4.cone.rmsd=rmsd.yai(impute.yai(rf.4.cone,newdata=rfy,method=\"closest\",observed=TRUE),scale=T)\nrf.4.most.rmsd=rmsd.yai(impute.yai(rf.4.most,newdata=rfy,method=\"closest\",observed=TRUE),scale=T)\nrf.4.wmax.rmsd=rmsd.yai(impute.yai(rf.4.wmax,newdata=rfy,method=\"closest\",observed=TRUE),scale=T)\nrf.4.rmsd=cbind(rf.4.all.rmsd,rf.4.cone.rmsd,rf.4.most.rmsd,rf.4.wmax.rmsd)\ncolnames(rf.4.rmsd)=c(\"ALL\",\"CONE\",\"MOST\",\"WMAX\")\nboxplot(rf.4.rmsd, notch=TRUE, main=\"Impute Max Species Ys\", xlab=\"YAI Object\", ylab=\"RMSD\", cex.axis=0.8)\nsummary(rf.4.rmsd)\npar(opar)\n\n\n# Compare RMSD in boxplots before and after x variable pruning\nopar <- par(mfrow=c(1,2), pty=\"s\", mar=c(1,4,3,2))\nrf.60.all.rmsd=rmsd.yai(impute.yai(rf.60.all,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.60.cone.rmsd=rmsd.yai(impute.yai(rf.60.cone,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.60.most.rmsd=rmsd.yai(impute.yai(rf.60.most,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.60.wmax.rmsd=rmsd.yai(impute.yai(rf.60.wmax,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.60.rmsd=cbind(rf.60.all.rmsd,rf.60.cone.rmsd,rf.60.most.rmsd,rf.60.wmax.rmsd)\ncolnames(rf.60.rmsd)=c(\"36\",\"22\",\"8\",\"4\")\nboxplot(rf.60.rmsd, notch=TRUE, main=\"All 60 Predictor Variables\", xlab=\"Number of Response Variables\", ylab=\"RMSD\", ylim=range(rf.rmsd))\nsummary(rf.60.rmsd)\n\nrf.all.rmsd=rmsd.yai(impute.yai(rf.all,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.cone.rmsd=rmsd.yai(impute.yai(rf.cone,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.most.rmsd=rmsd.yai(impute.yai(rf.most,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.wmax.rmsd=rmsd.yai(impute.yai(rf.wmax,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.rmsd=cbind(rf.all.rmsd,rf.cone.rmsd,rf.most.rmsd,rf.wmax.rmsd)\ncolnames(rf.rmsd)=c(\"36\",\"22\",\"8\",\"4\")\nboxplot(rf.rmsd, notch=TRUE, main=\"12 Selected Predictor Variables\", xlab=\"Number of Response Variables\", ylab=\"RMSD\")\nsummary(rf.rmsd)\npar(opar)\n\nrf.4.all.rmsd=rmsd.yai(impute.yai(rf.4.all,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.4.cone.rmsd=rmsd.yai(impute.yai(rf.4.cone,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.4.most.rmsd=rmsd.yai(impute.yai(rf.4.most,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.4.wmax.rmsd=rmsd.yai(impute.yai(rf.4.wmax,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.4.rmsd=cbind(rf.4.all.rmsd,rf.4.cone.rmsd,rf.4.most.rmsd,rf.4.wmax.rmsd)\ncolnames(rf.4.rmsd)=c(\"36 Ys\",\"22 Ys\",\"8 Ys\",\"WMax\")\nboxplot(rf.4.rmsd, notch=TRUE, main=\"4 Best X Variables\", xlab=\"YAI Object\", ylab=\"RMSD\", ylim=range(rf.rmsd))\nsummary(rf.4.rmsd)\npar(opar)\n\nyaiRFsummary(rf.wmax)\nyaiVarImp(rf.wmax) # Sorted by median decrease in Gini index\nyaVarImp(rf.wmax) # Sorted by mean decrease in Gini index\n\n# This boxplot shows TSRAI is least important, but I know ecologically that it's important (just\n# as I knew UTM Easting and Northing mattered in the CJRS paper), so I want to include it.\n# I want to include a figure like this in the paper, so I'll name it as a new function that I can edit.\n\nyaiVarImpError = function(rf, nTop=20)\n{\n  if (class(rf) != \"yai\") stop (\"arg must be of class yai\")\n  allImp = matrix(0, nrow=length(names(rf$ranForest)), ncol=length(xvars(rf)))\n  colnames(allImp) = xvars(rf)\n  rownames(allImp) = names(rf$ranForest)\n  \n  i = 0\n  for (rfObj in rf$ranForest)\n  {\n    i = i+1\n    allImp[i,] = importance(rfObj)[,\"MeanDecreaseAccuracy\"]\n  }\n  \n  allImp = data.frame(allImp)\n  nTop = min(ncol(allImp), nTop)\n  plt = par()$plt\n  oldplt = plt\n  plt[1] = .2\n  best = sort(apply(allImp, 2, median), decreasing = FALSE, index.return = TRUE)$ix[1:nTop]\n  boxplot(as.data.frame(allImp[,best]), horizontal=TRUE, par(plt=plt), las=1,\n          main=\"\", xlab=\"Mean Decrease Error\")\n  par(plt=oldplt)\n  invisible(list(allImp=allImp, best=best))\n}\nyaiVarImpGini = function(rf, nTop=20)\n{\n  if (class(rf) != \"yai\") stop (\"arg must be of class yai\")\n  allImp = matrix(0, nrow=length(names(rf$ranForest)), ncol=length(xvars(rf)))\n  colnames(allImp) = xvars(rf)\n  rownames(allImp) = names(rf$ranForest)\n  \n  i = 0\n  for (rfObj in rf$ranForest)\n  {\n    i = i+1\n    allImp[i,] = importance(rfObj)[,\"MeanDecreaseGini\"]\n  }\n  \n  allImp = data.frame(allImp)\n  nTop = min(ncol(allImp), nTop)\n  plt = par()$plt\n  oldplt = plt\n  plt[1] = .2\n  best = sort(apply(allImp, 2, median), decreasing = FALSE, index.return = TRUE)$ix[1:nTop]\n  boxplot(as.data.frame(allImp[,best]), horizontal=TRUE, par(plt=plt), las=1,\n          main=\"\", xlab=\"Mean Decrease Gini\")\n  par(plt=oldplt)\n  invisible(list(allImp=allImp, best=best))\n}\nopar <- par(mfrow=c(1,2), pty=\"m\", mar=c(4,10,1,1), cex=0.7)\nyaiVarImpError(rf.wmax) # Function to make a figure.\nyaiVarImpGini(rf.wmax) # Function to make a figure.\npar(opar)\n\n\n# Look at variable importance plots for individual variables.\nvarImpPlot(rf.wmax$ranForest[[1]])\nvarImpPlot(rf.wmax$ranForest[[2]])\nvarImpPlot(rf.wmax$ranForest[[3]])\nvarImpPlot(rf.wmax$ranForest[[4]])\n\n# The order of the x variables in the accuracy and genie index importance plots still doesn't match,\n# but at least in the case of the former they show gradual changes, rather than the stepped pattern\n# as with all 60 x variables.  Now I will compare all of the yaImpute methods.  I'll impute all y's,\n# but only report results for the 11 conifer species.\n\n# Compare RMSD using all 60 x's and all 36 y's\nx = spp[,37:100]\nbag=c(\"ASP\",\"N\",\"VEGN\",\"GNDN\")\nkeep=setdiff(colnames(x),bag)\nx=x[,keep]                     # Omit unwanted x's from consideration.\neuc.60=yai(x=x, y=y, method=\"euclidean\", k=k, ann=F)\nraw.60=yai(x=x, y=y, method=\"raw\", k=k, ann=F)\nmal.60=yai(x=x, y=y, method=\"mahalanobis\", k=k, ann=F)\nica.60=yai(x=x, y=y, method=\"ica\", k=k, ann=F)\nmsn.60=yai(x=x, y=y, method=\"msn\", k=k, ann=F)\nmsn2.60=yai(x=x, y=y, method=\"msn2\", k=k, ann=F)\ngnn.60=yai(x=x, y=y, method=\"gnn\", k=k, ann=F)\nrf.60=yai(x=x, y=y, method=\"randomForest\", k=k, ann=F, ntree=300*ncol(y))\nrf2.60=yai(x=x,y=rfy,method=\"randomForest\",k=k, ann=F, ntree=300*ncol(rfy))\n\n# Just plot statistics for the 22 conifer y's\nopar <- par(mfrow=c(2,1), pty=\"s\", mar=c(1,5,3,1))\neuc.60.rmsd=rmsd.yai(impute.yai(euc.60,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nraw.60.rmsd=rmsd.yai(impute.yai(raw.60,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nmal.60.rmsd=rmsd.yai(impute.yai(mal.60,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nica.60.rmsd=rmsd.yai(impute.yai(ica.60,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nmsn.60.rmsd=rmsd.yai(impute.yai(msn.60,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nmsn2.60.rmsd=rmsd.yai(impute.yai(msn2.60,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\ngnn.60.rmsd=rmsd.yai(impute.yai(gnn.60,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.60.rmsd=rmsd.yai(impute.yai(rf.60,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf2.60.rmsd=rmsd.yai(impute.yai(rf2.60,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nall.60.rmsd=cbind(euc.60.rmsd,raw.60.rmsd,mal.60.rmsd,ica.60.rmsd,msn.60.rmsd,msn2.60.rmsd,gnn.60.rmsd,rf.60.rmsd,rf2.60.rmsd)\ncolnames(all.60.rmsd)=c(\"EUC\",\"RAW\",\"MAL\",\"ICA\",\"MSN\",\"MSN2\",\"GNN\",\"RF\",\"RF2\")\nboxplot(all.60.rmsd, notch=TRUE, xlab=\"YAI Method\", ylab=\"RMSD\", main=\"All 60 X Variables\")\n\n# Rather than use 60 x's, achieve comparable RMSD using 12 selected x's and 4 best x's.  First the 12 x's:\nx = spp[,37:100]\nkeep = c(\"TSRAI\",\"STRATUM1\",\"IVAR\",\"HCV\",\"H05TH\",\"HAAD\",\"ISKEW\",\"HRANGE\",\"H25TH\",\"ELEV\",\"PCT2\",\"DENSITY\")\npred = x[,keep]\neuc=yai(x=pred, y=y, method=\"euclidean\", k=k, ann=F)\nraw=yai(x=pred, y=y, method=\"raw\", k=k, ann=F)\nmal=yai(x=pred, y=y, method=\"mahalanobis\", k=k, ann=F)\nica=yai(x=pred, y=y, method=\"ica\", k=k, ann=F)\nmsn=yai(x=pred, y=y, method=\"msn\", k=k, ann=F)\nmsn2=yai(x=pred, y=y, method=\"msn2\", k=k, ann=F)\ngnn=yai(x=pred, y=y, method=\"gnn\", k=k, ann=F)\nrf=yai(x=pred, y=y, method=\"randomForest\", k=k, ann=F, ntree=300*ncol(y))\nrf2=yai(x=pred,y=rfy,method=\"randomForest\",k=k, ann=F, ntree=300*ncol(rfy))\n\neuc.rmsd=rmsd.yai(impute.yai(euc,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nraw.rmsd=rmsd.yai(impute.yai(raw,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nmal.rmsd=rmsd.yai(impute.yai(mal,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nica.rmsd=rmsd.yai(impute.yai(ica,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nmsn.rmsd=rmsd.yai(impute.yai(msn,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nmsn2.rmsd=rmsd.yai(impute.yai(msn2,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\ngnn.rmsd=rmsd.yai(impute.yai(gnn,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.rmsd=rmsd.yai(impute.yai(rf,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf2.rmsd=rmsd.yai(impute.yai(rf2,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nall.rmsd=cbind(euc.rmsd,raw.rmsd,mal.rmsd,ica.rmsd,msn.rmsd,msn2.rmsd,gnn.rmsd,rf.rmsd,rf2.rmsd)\ncolnames(all.rmsd)=c(\"EUC\",\"RAW\",\"MAL\",\"ICA\",\"MSN\",\"MSN2\",\"GNN\",\"RF\",\"RF2\")\nboxplot(all.rmsd, notch=TRUE, xlab=\"Imputation Method\", ylab=\"RMSD\")\n\n# Now the 4 best x's.\nx = spp[,37:100]\nkeep = c(\"HRANGE\",\"H25TH\",\"PCT2\",\"DENSITY\")\npred.4 = x[,keep]\neuc.4=yai(x=pred.4, y=y, method=\"euclidean\", k=k, ann=F)\nraw.4=yai(x=pred.4, y=y, method=\"raw\", k=k, ann=F)\nmal.4=yai(x=pred.4, y=y, method=\"mahalanobis\", k=k, ann=F)\nica.4=yai(x=pred.4, y=y, method=\"ica\", k=k, ann=F)\nmsn.4=yai(x=pred.4, y=y, method=\"msn\", k=k, ann=F)\nmsn2.4=yai(x=pred.4, y=y, method=\"msn2\", k=k, ann=F)\ngnn.4=yai(x=pred.4, y=y, method=\"gnn\", k=k, ann=F)\nrf.4=yai(x=pred.4, y=y, method=\"randomForest\", k=k, ann=F, ntree=300*ncol(y))\nrf2.4=yai(x=pred.4,y=rfy,method=\"randomForest\",k=k, ann=F, ntree=300*ncol(rfy))\n\neuc.4.rmsd=rmsd.yai(impute.yai(euc.4,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nraw.4.rmsd=rmsd.yai(impute.yai(raw.4,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nmal.4.rmsd=rmsd.yai(impute.yai(mal.4,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nica.4.rmsd=rmsd.yai(impute.yai(ica.4,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nmsn.4.rmsd=rmsd.yai(impute.yai(msn.4,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nmsn2.4.rmsd=rmsd.yai(impute.yai(msn2.4,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\ngnn.4.rmsd=rmsd.yai(impute.yai(gnn.4,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.4.rmsd=rmsd.yai(impute.yai(rf.4,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf2.4.rmsd=rmsd.yai(impute.yai(rf2.4,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nall.4.rmsd=cbind(euc.4.rmsd,raw.4.rmsd,mal.4.rmsd,ica.4.rmsd,msn.4.rmsd,msn2.4.rmsd,gnn.4.rmsd,rf.4.rmsd,rf2.4.rmsd)\ncolnames(all.4.rmsd)=c(\"EUC\",\"RAW\",\"MAL\",\"ICA\",\"MSN\",\"MSN2\",\"GNN\",\"RF\",\"RF2\")\nboxplot(all.4.rmsd, notch=TRUE, xlab=\"YAI Method\", ylab=\"RMSD\", main=\"4 Best X Variables\", ylim=range(all.60.rmsd))\npar(opar)\n\n# Look at the correlations.\neuc.60.cor=cor.yai(impute.yai(euc.60,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nraw.60.cor=cor.yai(impute.yai(raw.60,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nmal.60.cor=cor.yai(impute.yai(mal.60,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nica.60.cor=cor.yai(impute.yai(ica.60,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nmsn.60.cor=cor.yai(impute.yai(msn.60,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nmsn2.60.cor=cor.yai(impute.yai(msn2.60,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\ngnn.60.cor=cor.yai(impute.yai(gnn.60,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.60.cor=cor.yai(impute.yai(rf.60,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf2.60.cor=cor.yai(impute.yai(rf2.60,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nall.60.cor=cbind(euc.60.cor,raw.60.cor,mal.60.cor,ica.60.cor,msn.60.cor,msn2.60.cor,gnn.60.cor,rf.60.cor,rf2.60.cor)\ncolnames(all.60.cor)=c(\"EUC\",\"RAW\",\"MAL\",\"ICA\",\"MSN\",\"MSN2\",\"GNN\",\"RF\",\"RF2\")\nboxplot(all.60.cor, notch=TRUE, xlab=\"YAI Method\", ylab=\"Pearson Correlation\", ylim=range(all.cor))\n\neuc.cor=cor.yai(impute.yai(euc,newdata=y[,cone],method=\"closest\",observed=TRUE))\nraw.cor=cor.yai(impute.yai(raw,newdata=y[,cone],method=\"closest\",observed=TRUE))\nmal.cor=cor.yai(impute.yai(mal,newdata=y[,cone],method=\"closest\",observed=TRUE))\nica.cor=cor.yai(impute.yai(ica,newdata=y[,cone],method=\"closest\",observed=TRUE))\nmsn.cor=cor.yai(impute.yai(msn,newdata=y[,cone],method=\"closest\",observed=TRUE))\nmsn2.cor=cor.yai(impute.yai(msn2,newdata=y[,cone],method=\"closest\",observed=TRUE))\ngnn.cor=cor.yai(impute.yai(gnn,newdata=y[,cone],method=\"closest\",observed=TRUE))\nrf.cor=cor.yai(impute.yai(rf,newdata=y[,cone],method=\"closest\",observed=TRUE))\nrf2.cor=cor.yai(impute.yai(rf2,newdata=y[,cone],method=\"closest\",observed=TRUE))\nall.cor=cbind(euc.cor,raw.cor,mal.cor,ica.cor,msn.cor,msn2.cor,gnn.cor,rf.cor,rf2.cor)\ncolnames(all.cor)=c(\"EUC\",\"RAW\",\"MAL\",\"ICA\",\"MSN\",\"MSN2\",\"GNN\",\"RF\",\"RF2\")\nboxplot(all.cor, notch=TRUE, xlab=\"YAI Method\", ylab=\"Pearson Correlation\")\n\neuc.4.cor=cor.yai(impute.yai(euc.4,newdata=y[,cone],method=\"closest\",observed=TRUE))\nraw.4.cor=cor.yai(impute.yai(raw.4,newdata=y[,cone],method=\"closest\",observed=TRUE))\nmal.4.cor=cor.yai(impute.yai(mal.4,newdata=y[,cone],method=\"closest\",observed=TRUE))\nica.4.cor=cor.yai(impute.yai(ica.4,newdata=y[,cone],method=\"closest\",observed=TRUE))\nmsn.4.cor=cor.yai(impute.yai(msn.4,newdata=y[,cone],method=\"closest\",observed=TRUE))\nmsn2.4.cor=cor.yai(impute.yai(msn2.4,newdata=y[,cone],method=\"closest\",observed=TRUE))\ngnn.4.cor=cor.yai(impute.yai(gnn.4,newdata=y[,cone],method=\"closest\",observed=TRUE))\nrf.4.cor=cor.yai(impute.yai(rf.4,newdata=y[,cone],method=\"closest\",observed=TRUE))\nrf2.4.cor=cor.yai(impute.yai(rf2.4,newdata=y[,cone],method=\"closest\",observed=TRUE))\nall.4.cor=cbind(euc.4.cor,raw.4.cor,mal.4.cor,ica.4.cor,msn.4.cor,msn2.4.cor,gnn.4.cor,rf.4.cor,rf2.4.cor)\ncolnames(all.4.cor)=c(\"EUC\",\"RAW\",\"MAL\",\"ICA\",\"MSN\",\"MSN2\",\"GNN\",\"RF\",\"RF2\")\nboxplot(all.4.cor, notch=TRUE, xlab=\"YAI Method\", ylab=\"Pearson Correlation\", ylim=range(all.cor))\n\n# Now I'll test how well imputation works with YAI objects based on just 22 Ys of interest.\neuc.22=yai(x=pred, y=y[,cone], method=\"euclidean\", k=k, ann=F)\nraw.22=yai(x=pred, y=y[,cone], method=\"raw\", k=k, ann=F)\nmal.22=yai(x=pred, y=y[,cone], method=\"mahalanobis\", k=k, ann=F)\nica.22=yai(x=pred, y=y[,cone], method=\"ica\", k=k, ann=F)\nmsn.22=yai(x=pred, y=y[,cone], method=\"msn\", k=k, ann=F)\nmsn2.22=yai(x=pred, y=y[,cone], method=\"msn2\", k=k, ann=F)\ngnn.22=yai(x=pred, y=y[,cone], method=\"gnn\", k=k, ann=F)\nrf.22=yai(x=pred, y=y[,cone], method=\"randomForest\", k=k, ann=F, ntree=300*ncol(y))\n# rf2=yai(x=pred,y=rfy,method=\"randomForest\",k=k, ann=F, ntree=300*ncol(rfy))  # Already done.\n\neuc.22.rmsd=rmsd.yai(impute.yai(euc.22,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nraw.22.rmsd=rmsd.yai(impute.yai(raw.22,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nmal.22.rmsd=rmsd.yai(impute.yai(mal.22,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nica.22.rmsd=rmsd.yai(impute.yai(ica.22,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nmsn.22.rmsd=rmsd.yai(impute.yai(msn.22,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nmsn2.22.rmsd=rmsd.yai(impute.yai(msn2.22,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\ngnn.22.rmsd=rmsd.yai(impute.yai(gnn.22,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf.22.rmsd=rmsd.yai(impute.yai(rf.22,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nrf2.rmsd=rmsd.yai(impute.yai(rf2,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\nall.22.rmsd=cbind(euc.22.rmsd,raw.22.rmsd,mal.22.rmsd,ica.22.rmsd,msn.22.rmsd,msn2.22.rmsd,gnn.22.rmsd,rf.22.rmsd,rf2.rmsd)\ncolnames(all.22.rmsd)=c(\"EUC\",\"RAW\",\"MAL\",\"ICA\",\"MSN\",\"MSN2\",\"GNN\",\"RF\",\"RF2\")\nboxplot(all.22.rmsd, notch=TRUE, xlab=\"YAI Method\", ylab=\"RMSD\")\n\n# However, vegan (for GNN) deleted 12 rows with Y-variable sums < 0.01 (because I didn't include the \n# non-zero BA and TD totals), so the comparison is unfair.  So I should stick to YAI objects with 36 Ys.\n# Based on these results, which show the same pattern between boxplots for all y's and most common\n# conifer y's as for the 11 conifer spp., I will use the 11 conifer spp as my evaluation criteria.\n\n# Although not recorded here, the patterns between boxplots when correlating all y's, or just\n# the most common conifer y's, was the same as for the 11 conifers.  I'll save the imputed values\n# by each method as objects, based on the same yai objects.\n\neuc.imp = impute.yai(euc,newdata=y,method=\"closest\",observed=TRUE)\nraw.imp = impute.yai(raw,newdata=y,method=\"closest\",observed=TRUE)\nmal.imp = impute.yai(mal,newdata=y,method=\"closest\",observed=TRUE)\nica.imp = impute.yai(ica,newdata=y,method=\"closest\",observed=TRUE)\nmsn.imp = impute.yai(msn,newdata=y,method=\"closest\",observed=TRUE)\nmsn2.imp = impute.yai(msn2,newdata=y,method=\"closest\",observed=TRUE)\ngnn.imp = impute.yai(gnn,newdata=y,method=\"closest\",observed=TRUE)\nrf.imp = impute.yai(rf,newdata=y,method=\"closest\",observed=TRUE)\nrf2.imp = impute.yai(rf2,newdata=y,method=\"closest\",observed=TRUE)\n\n\n## Now I'll produce scatterplots of observed vs. imputed by the nine methods.\n# I'll use the \"cone\" variables to get a good distribution of predictions.\nopar <- par(mfrow=c(3,3))\nplot(euc.imp$Total_BA, euc.imp$Total_BA.o, xlim=range(euc.imp$Total_BA.o), main=\"Euclidean\",\n     sub=paste(\"r=\",round(cor(euc.imp$Total_BA, euc.imp$Total_BA.o),2)), xlab=expression(paste(\"Imputed Basal Area (\", m^2, \"/ha)\")), \n     ylab=expression(paste(\"Observed Basal Area (\", m^2, \"/ha)\")))\nabline(0,1)\nplot(raw.imp$Total_BA, raw.imp$Total_BA.o, xlim=range(raw.imp$Total_BA.o), main=\"Raw\",\n     sub=paste(\"r=\",round(cor(raw.imp$Total_BA, raw.imp$Total_BA.o),2)), xlab=expression(paste(\"Imputed Basal Area (\", m^2, \"/ha)\")), \n     ylab=expression(paste(\"Observed Basal Area (\", m^2, \"/ha)\")))\nabline(0,1)\nplot(mal.imp$Total_BA, mal.imp$Total_BA.o, xlim=range(mal.imp$Total_BA.o), main=\"Mahalanobis\",\n     sub=paste(\"r=\",round(cor(mal.imp$Total_BA, mal.imp$Total_BA.o),2)), xlab=expression(paste(\"Imputed Basal Area (\", m^2, \"/ha)\")), \n     ylab=expression(paste(\"Observed Basal Area (\", m^2, \"/ha)\")))\nabline(0,1)\nplot(ica.imp$Total_BA, ica.imp$Total_BA.o, xlim=range(ica.imp$Total_BA.o), main=\"ICA\",\n     sub=paste(\"r=\",round(cor(ica.imp$Total_BA, ica.imp$Total_BA.o),2)), xlab=expression(paste(\"Imputed Basal Area (\", m^2, \"/ha)\")), \n     ylab=expression(paste(\"Observed Basal Area (\", m^2, \"/ha)\")))\nabline(0,1)\nplot(msn.imp$Total_BA, msn.imp$Total_BA.o, xlim=range(msn.imp$Total_BA.o), main=\"MSN\",\n     sub=paste(\"r=\",round(cor(msn.imp$Total_BA, msn.imp$Total_BA.o),2)), xlab=expression(paste(\"Imputed Basal Area (\", m^2, \"/ha)\")), \n     ylab=expression(paste(\"Observed Basal Area (\", m^2, \"/ha)\")))\nabline(0,1)\nplot(msn2.imp$Total_BA, msn2.imp$Total_BA.o, xlim=range(msn2.imp$Total_BA.o), main=\"MSN2\",\n     sub=paste(\"r=\",round(cor(msn2.imp$Total_BA, msn2.imp$Total_BA.o),2)), xlab=expression(paste(\"Imputed Basal Area (\", m^2, \"/ha)\")), \n     ylab=expression(paste(\"Observed Basal Area (\", m^2, \"/ha)\")))\nabline(0,1)\nplot(gnn.imp$Total_BA, gnn.imp$Total_BA.o, xlim=range(gnn.imp$Total_BA.o), main=\"GNN\",\n     sub=paste(\"r=\",round(cor(gnn.imp$Total_BA, gnn.imp$Total_BA.o),2)), xlab=expression(paste(\"Imputed Basal Area (\", m^2, \"/ha)\")), \n     ylab=expression(paste(\"Observed Basal Area (\", m^2, \"/ha)\")))\nabline(0,1)\nplot(rf.imp$Total_BA, rf.imp$Total_BA.o, xlim=range(rf.imp$Total_BA.o), main=\"RF\",\n     sub=paste(\"r=\",round(cor(rf.imp$Total_BA, rf.imp$Total_BA.o),2)), xlab=expression(paste(\"Imputed Basal Area (\", m^2, \"/ha)\")), \n     ylab=expression(paste(\"Observed Basal Area (\", m^2, \"/ha)\")))\nabline(0,1)\nplot(rf2.imp$Total_BA, rf2.imp$Total_BA.o, xlim=range(rf2.imp$Total_BA.o), main=\"RF2\",\n     sub=paste(\"r=\",round(cor(rf2.imp$Total_BA, rf2.imp$Total_BA.o),2)), xlab=expression(paste(\"Imputed Basal Area (\", m^2, \"/ha)\")), \n     ylab=expression(paste(\"Observed Basal Area (\", m^2, \"/ha)\")))\nabline(0,1)\npar(opar)\n\nopar <- par(mfrow=c(3,3))\nplot(euc.imp$Total_TD, euc.imp$Total_TD.o, xlim=range(euc.imp$Total_TD.o), main=\"Euclidean\",\n     sub=paste(\"r=\",round(cor(euc.imp$Total_TD, euc.imp$Total_TD.o),2)), xlab=\"Imputed Tree Density (trees/ha)\",\n     ylab=\"Observed Tree Density (trees/ha)\")\nabline(0,1)\nplot(raw.imp$Total_TD, raw.imp$Total_TD.o, xlim=range(raw.imp$Total_TD.o), main=\"Raw\",\n     sub=paste(\"r=\",round(cor(raw.imp$Total_TD, raw.imp$Total_TD.o),2)), xlab=\"Imputed Tree Density (trees/ha)\",\n     ylab=\"Observed Tree Density (trees/ha)\")\nabline(0,1)\nplot(mal.imp$Total_TD, mal.imp$Total_TD.o, xlim=range(mal.imp$Total_TD.o), main=\"Mahalanobis\",\n     sub=paste(\"r=\",round(cor(mal.imp$Total_TD, mal.imp$Total_TD.o),2)), xlab=\"Imputed Tree Density (trees/ha)\",\n     ylab=\"Observed Tree Density (trees/ha)\")\nabline(0,1)\nplot(ica.imp$Total_TD, ica.imp$Total_TD.o, xlim=range(ica.imp$Total_TD.o), main=\"ICA\",\n     sub=paste(\"r=\",round(cor(ica.imp$Total_TD, ica.imp$Total_TD.o),2)), xlab=\"Imputed Tree Density (trees/ha)\",\n     ylab=\"Observed Tree Density (trees/ha)\")\nabline(0,1)\nplot(msn.imp$Total_TD, msn.imp$Total_TD.o, xlim=range(msn.imp$Total_TD.o), main=\"MSN\",\n     sub=paste(\"r=\",round(cor(msn.imp$Total_TD, msn.imp$Total_TD.o),2)), xlab=\"Imputed Tree Density (trees/ha)\",\n     ylab=\"Observed Tree Density (trees/ha)\")\nabline(0,1)\nplot(msn2.imp$Total_TD, msn2.imp$Total_TD.o, xlim=range(msn2.imp$Total_TD.o), main=\"MSN2\",\n     sub=paste(\"r=\",round(cor(msn2.imp$Total_TD, msn2.imp$Total_TD.o),2)), xlab=\"Imputed Tree Density (trees/ha)\",\n     ylab=\"Observed Tree Density (trees/ha)\")\nabline(0,1)\nplot(gnn.imp$Total_TD, gnn.imp$Total_TD.o, xlim=range(gnn.imp$Total_TD.o), main=\"GNN\",\n     sub=paste(\"r=\",round(cor(gnn.imp$Total_TD, gnn.imp$Total_TD.o),2)), xlab=\"Imputed Tree Density (trees/ha)\",\n     ylab=\"Observed Tree Density (trees/ha)\")\nabline(0,1)\nplot(rf.imp$Total_TD, rf.imp$Total_TD.o, xlim=range(rf.imp$Total_TD.o), main=\"RF\",\n     sub=paste(\"r=\",round(cor(rf.imp$Total_TD, rf.imp$Total_TD.o),2)), xlab=\"Imputed Tree Density (trees/ha)\",\n     ylab=\"Observed Tree Density (trees/ha)\")\nabline(0,1)\nplot(rf2.imp$Total_TD, rf2.imp$Total_TD.o, xlim=range(rf2.imp$Total_TD.o), main=\"RF2\",\n     sub=paste(\"r=\",round(cor(rf2.imp$Total_TD, rf2.imp$Total_TD.o),2)), xlab=\"Imputed Tree Density (trees/ha)\",\n     ylab=\"Observed Tree Density (trees/ha)\")\nabline(0,1)\npar(opar)\n\n## I compared my total BA and TD imputations to those predicted in my CJRS paper.\n\nplot(rf2.imp$Total_BA.o, pred.ba.cor)\n\n## Now I'll plot the total BA and total TD for the top 6 species, in a 2x3 plot.\nba6=names(sort(apply(basp,2,sum),decreasing = TRUE))[1:6]\ntd6=names(sort(apply(tdsp,2,sum),decreasing = TRUE))[1:6]\nplot(euc.imp,vars=ba6)\nplot(euc.imp,vars=td6)\nplot(raw.imp,vars=ba6)\nplot(raw.imp,vars=td6)\nplot(mal.imp,vars=ba6)\nplot(mal.imp,vars=td6)\nplot(ica.imp,vars=ba6)\nplot(ica.imp,vars=td6)\nplot(msn.imp,vars=ba6)\nplot(msn.imp,vars=td6)\nplot(msn2.imp,vars=ba6)\nplot(msn2.imp,vars=td6)\nplot(gnn.imp,vars=ba6)\nplot(gnn.imp,vars=td6)\nplot(rf.imp,vars=ba6)\nplot(rf.imp,vars=td6)\nplot(rf2.imp,vars=ba6)\nplot(rf2.imp,vars=td6)\n\n\n## Now I'll compare the best methods using scatterplots.\nrmsd=compare.yai(euc.imp,raw.imp,mal.imp,ica.imp,msn.imp,msn2.imp,gnn.imp,rf.imp,rf2.imp)\napply(rmsd,2,mean)[,cone]\nplot(rmsd)\nplot(compare.yai(euc.imp,raw.imp,mal.imp,ica.imp,msn.imp,msn2.imp,gnn.imp,rf.imp,rf2.imp,method=\"cor\"))\n\n\n## I can also impute just on the yvars in the rf2 object, and build a contingency table.\n\nrfim = impute.yai(rf2,vars=yvars(rf2),method=\"closest\",observed=TRUE)\nplot(rfim)\npar(mfcol=c(2,2))\nfor (i in 1:4) hist(rfim[,i],main=colnames(rfim)[i])\n\ntable(rfim[,5],rfim[,7])\ntable(rfim[,6],rfim[,8])\n\n\n## Now I need to map the predictions.  Jeff produced 30 m asciigrid text files that I converted to grids\n# in Arc for display purposes.\nasciigrid density.asc density float\nasciigrid elev.asc elev float\nasciigrid h05th.asc h05th float\nasciigrid h25th.asc h25th float\nasciigrid haad.asc haad float\nasciigrid hcv.asc hcv float\nasciigrid hrange.asc hrange float\nasciigrid iskew.asc iskew float\nasciigrid ivar.asc ivar float\nasciigrid pct2.asc pct2 float\nasciigrid stratum1.asc stratum1 float\nasciigrid trasp.asc tsrai float\n\n# For Moscow Mt.\nasciigrid density.asc density float\nasciigrid dem30.asc elev float\nasciigrid h05th.asc h05th float\nasciigrid h25th.asc h25th float\nasciigrid haad.asc haad float\nasciigrid hcv.asc hcv float\nasciigrid hrange.asc hrange float\nasciigrid iskew.asc iskew float\nasciigrid ivar.asc ivar float\nasciigrid pct2.asc pct2 float\nasciigrid stratum1.asc stratum1 float\nasciigrid trasp.asc tsrai float\n\n# Note that there are a few nodata (-9999) gaps.\n\n# Now I'll use Nick's AsciiGridImpute command.\nxlist = list(DENSITY=\"C:/data/imputation/sj/density.asc\", ELEV=\"C:/data/imputation/sj/elev.asc\",\n             H05TH=\"C:/data/imputation/sj/h05th.asc\", H25TH=\"C:/data/imputation/sj/h25th.asc\",\n             HAAD=\"C:/data/imputation/sj/haad.asc\", HCV=\"C:/data/imputation/sj/hcv.asc\",\n             HRANGE=\"C:/data/imputation/sj/hrange.asc\", ISKEW=\"C:/data/imputation/sj/iskew.asc\",\n             IVAR=\"C:/data/imputation/sj/ivar.asc\", PCT2=\"C:/data/imputation/sj/pct2.asc\",\n             STRATUM1=\"C:/data/imputation/sj/stratum1.asc\", TSRAI=\"C:/data/imputation/sj/trasp.asc\")\noutlist = list(PIPO_BA=\"C:/data/imputation/sj/pipo_ba.asc\", PSME_BA=\"C:/data/imputation/sj/psme_ba.asc\",\n               LAOC_BA=\"C:/data/imputation/sj/laoc_ba.asc\", PICO_BA=\"C:/data/imputation/sj/pico_ba.asc\",\n               ABGR_BA=\"C:/data/imputation/sj/abgr_ba.asc\", PIMO_BA=\"C:/data/imputation/sj/pimo_ba.asc\",\n               THPL_BA=\"C:/data/imputation/sj/thpl_ba.asc\", TSHE_BA=\"C:/data/imputation/sj/tshe_ba.asc\",\n               PIEN_BA=\"C:/data/imputation/sj/pien_ba.asc\", ABLA_BA=\"C:/data/imputation/sj/abla_ba.asc\",\n               TSME_BA=\"C:/data/imputation/sj/tsme_ba.asc\", Total_BA=\"C:/data/imputation/sj/total_ba.asc\",\n               PIPO_TD=\"C:/data/imputation/sj/pipo_td.asc\", PSME_TD=\"C:/data/imputation/sj/psme_td.asc\",\n               LAOC_TD=\"C:/data/imputation/sj/laoc_td.asc\", PICO_TD=\"C:/data/imputation/sj/pico_td.asc\",\n               ABGR_TD=\"C:/data/imputation/sj/abgr_td.asc\", PIMO_TD=\"C:/data/imputation/sj/pimo_td.asc\",\n               THPL_TD=\"C:/data/imputation/sj/thpl_td.asc\", TSHE_TD=\"C:/data/imputation/sj/tshe_td.asc\",\n               PIEN_TD=\"C:/data/imputation/sj/pien_td.asc\", ABLA_TD=\"C:/data/imputation/sj/abla_td.asc\",\n               TSME_TD=\"C:/data/imputation/sj/tsme_td.asc\", Total_TD=\"C:/data/imputation/sj/total_td.asc\",\n               ACGL_BA=\"C:/data/imputation/sj/acgl_ba.asc\", BEOC_BA=\"C:/data/imputation/sj/beoc_ba.asc\",\n               POBA_BA=\"C:/data/imputation/sj/poba_ba.asc\", POTR_BA=\"C:/data/imputation/sj/potr_ba.asc\",\n               SAEX_BA=\"C:/data/imputation/sj/saex_ba.asc\", UNKN_BA=\"C:/data/imputation/sj/unkn_ba.asc\",\n               ACGL_TD=\"C:/data/imputation/sj/acgl_td.asc\", BEOC_TD=\"C:/data/imputation/sj/beoc_td.asc\",\n               POBA_TD=\"C:/data/imputation/sj/poba_td.asc\", POTR_TD=\"C:/data/imputation/sj/potr_td.asc\",\n               SAEX_TD=\"C:/data/imputation/sj/saex_td.asc\", UNKN_TD=\"C:/data/imputation/sj/unkn_td.asc\")\nAsciiGridImpute(rf2, xlist, outlist, ancillaryData=y)\n\n# Moscow Mt...\nxlist = list(DENSITY=\"C:/data/imputation/mm/density.asc\", ELEV=\"C:/data/imputation/mm/dem30.asc\",\n             H05TH=\"C:/data/imputation/mm/h05th.asc\", H25TH=\"C:/data/imputation/mm/h25th.asc\",\n             HAAD=\"C:/data/imputation/mm/haad.asc\", HCV=\"C:/data/imputation/mm/hcv.asc\",\n             HRANGE=\"C:/data/imputation/mm/hrange.asc\", ISKEW=\"C:/data/imputation/mm/iskew.asc\",\n             IVAR=\"C:/data/imputation/mm/ivar.asc\", PCT2=\"C:/data/imputation/mm/pct2.asc\",\n             STRATUM1=\"C:/data/imputation/mm/stratum1.asc\", TSRAI=\"C:/data/imputation/mm/trasp.asc\")\noutlist = list(PIPO_BA=\"C:/data/imputation/mm/pipo_ba.asc\", PSME_BA=\"C:/data/imputation/mm/psme_ba.asc\",\n               LAOC_BA=\"C:/data/imputation/mm/laoc_ba.asc\", PICO_BA=\"C:/data/imputation/mm/pico_ba.asc\",\n               ABGR_BA=\"C:/data/imputation/mm/abgr_ba.asc\", PIMO_BA=\"C:/data/imputation/mm/pimo_ba.asc\",\n               THPL_BA=\"C:/data/imputation/mm/thpl_ba.asc\", TSHE_BA=\"C:/data/imputation/mm/tshe_ba.asc\",\n               PIEN_BA=\"C:/data/imputation/mm/pien_ba.asc\", ABLA_BA=\"C:/data/imputation/mm/abla_ba.asc\",\n               TSME_BA=\"C:/data/imputation/mm/tsme_ba.asc\", Total_BA=\"C:/data/imputation/mm/total_ba.asc\",\n               PIPO_TD=\"C:/data/imputation/mm/pipo_td.asc\", PSME_TD=\"C:/data/imputation/mm/psme_td.asc\",\n               LAOC_TD=\"C:/data/imputation/mm/laoc_td.asc\", PICO_TD=\"C:/data/imputation/mm/pico_td.asc\",\n               ABGR_TD=\"C:/data/imputation/mm/abgr_td.asc\", PIMO_TD=\"C:/data/imputation/mm/pimo_td.asc\",\n               THPL_TD=\"C:/data/imputation/mm/thpl_td.asc\", TSHE_TD=\"C:/data/imputation/mm/tshe_td.asc\",\n               PIEN_TD=\"C:/data/imputation/mm/pien_td.asc\", ABLA_TD=\"C:/data/imputation/mm/abla_td.asc\",\n               TSME_TD=\"C:/data/imputation/mm/tsme_td.asc\", Total_TD=\"C:/data/imputation/mm/total_td.asc\",\n               ACGL_BA=\"C:/data/imputation/mm/acgl_ba.asc\", BEOC_BA=\"C:/data/imputation/mm/beoc_ba.asc\",\n               POBA_BA=\"C:/data/imputation/mm/poba_ba.asc\", POTR_BA=\"C:/data/imputation/mm/potr_ba.asc\",\n               SAEX_BA=\"C:/data/imputation/mm/saex_ba.asc\", UNKN_BA=\"C:/data/imputation/mm/unkn_ba.asc\",\n               ACGL_TD=\"C:/data/imputation/mm/acgl_td.asc\", BEOC_TD=\"C:/data/imputation/mm/beoc_td.asc\",\n               POBA_TD=\"C:/data/imputation/mm/poba_td.asc\", POTR_TD=\"C:/data/imputation/mm/potr_td.asc\",\n               SAEX_TD=\"C:/data/imputation/mm/saex_td.asc\", UNKN_TD=\"C:/data/imputation/mm/unkn_td.asc\")\nAsciiGridImpute(rf2, xlist, outlist, ancillaryData=y)\n\n# This took less than a couple of hours to run...\n\n# Now, in Arc, I'll also convert these to grids for display purposes.\nasciigrid pipo_ba.asc pipo_ba float\nasciigrid psme_ba.asc psme_ba float\nasciigrid laoc_ba.asc laoc_ba float\nasciigrid pico_ba.asc pico_ba float\nasciigrid abgr_ba.asc abgr_ba float\nasciigrid pimo_ba.asc pimo_ba float\nasciigrid thpl_ba.asc thpl_ba float\nasciigrid tshe_ba.asc tshe_ba float\nasciigrid pien_ba.asc pien_ba float\nasciigrid abla_ba.asc abla_ba float\nasciigrid tsme_ba.asc tsme_ba float\nasciigrid total_ba.asc total_ba float\nasciigrid pipo_td.asc pipo_td float\nasciigrid psme_td.asc psme_td float\nasciigrid laoc_td.asc laoc_td float\nasciigrid pico_td.asc pico_td float\nasciigrid abgr_td.asc abgr_td float\nasciigrid pimo_td.asc pimo_td float\nasciigrid thpl_td.asc thpl_td float\nasciigrid tshe_td.asc tshe_td float\nasciigrid pien_td.asc pien_td float\nasciigrid abla_td.asc abla_td float\nasciigrid tsme_td.asc tsme_td float\nasciigrid total_td.asc total_td float\nasciigrid acgl_ba.asc acgl_ba float\nasciigrid beoc_ba.asc beoc_ba float\nasciigrid poba_ba.asc poba_ba float\nasciigrid potr_ba.asc potr_ba float\nasciigrid saex_ba.asc saex_ba float\nasciigrid unkn_ba.asc unkn_ba float\nasciigrid acgl_td.asc acgl_td float\nasciigrid beoc_td.asc beoc_td float\nasciigrid poba_td.asc poba_td float\nasciigrid potr_td.asc potr_td float\nasciigrid saex_td.asc saex_td float\nasciigrid unkn_td.asc unkn_td float\n\nI need to validate the maps against the plot observations.  I'll use Jeff's getgridvalue AML to extract\nthe mapped target values at the plot centers.\n\ncopy ..\\..\\..\\ath_data\\lidar\\sj\\sj_plots sjpltcen\ngetgridvalue sjpltcen pipo_ba psme_ba laoc_ba pico_ba abgr_ba pimo_ba thpl_ba tshe_ba pien_ba abla_ba tsme_ba total_ba\ngetgridvalue sjpltcen pipo_td psme_td laoc_td pico_td abgr_td pimo_td thpl_td tshe_td pien_td abla_td tsme_td total_td\ninfodbase sjpltcen.pat sjpltcen.dbf\n\ncopy ..\\..\\..\\ath_data\\lidar\\mm\\mm_plots mmpltcen\ngetgridvalue mmpltcen pipo_ba psme_ba laoc_ba pico_ba abgr_ba pimo_ba thpl_ba tshe_ba pien_ba abla_ba tsme_ba total_ba\ngetgridvalue mmpltcen pipo_td psme_td laoc_td pico_td abgr_td pimo_td thpl_td tshe_td pien_td abla_td tsme_td total_td\ninfodbase mmpltcen.pat mmpltcen.dbf\n\n# I opened the above two .dbf files in Excel, and combined them into a single spreadsheet.\nmap=read.csv(\"imputation_map_validation.csv\",header=TRUE,row.names=1,as.is=TRUE)\nmap.spp=map[,cone]\nobs.spp=y[,cone]\n\nfor (i in 1:22) {\n  print(paste(i, cone[i], cor(map.spp[,i], obs.spp[,i])))\n}\n[1] \"1 PIPO_BA 0.566364047230754\"\n[1] \"2 PSME_BA 0.697425948184443\"\n[1] \"3 LAOC_BA 0.671048796706468\"\n[1] \"4 PICO_BA 0.946740625871749\"\n[1] \"5 ABGR_BA 0.813244295507027\"\n[1] \"6 PIMO_BA 0.683163237566995\"\n[1] \"7 THPL_BA 0.886179252761268\"\n[1] \"8 TSHE_BA 0.809482558184703\"\n[1] \"9 PIEN_BA 0.795875399458872\"\n[1] \"10 ABLA_BA 0.975496470334521\"\n[1] \"11 TSME_BA 0.999999999999962\"\n[1] \"12 PIPO_TD 0.753903648804568\"\n[1] \"13 PSME_TD 0.776095765376965\"\n[1] \"14 LAOC_TD 0.770027606460391\"\n[1] \"15 PICO_TD 0.984759419079706\"\n[1] \"16 ABGR_TD 0.737865026498768\"\n[1] \"17 PIMO_TD 0.830280814701843\"\n[1] \"18 THPL_TD 0.711148679894946\"\n[1] \"19 TSHE_TD 0.846664093187567\"\n[1] \"20 PIEN_TD 0.895827124129878\"\n[1] \"21 ABLA_TD 0.981225825146314\"\n[1] \"22 TSME_TD 0.99999999999973\"\n\n# What about SJ alone?\nmap.sj = map.spp[1:81,]\nobs.sj = obs.spp[1:81,]\nfor (i in 1:22) {\n  print(paste(i, cone[i], cor(map.sj[,i], obs.sj[,i])))\n}\n[1] \"1 PIPO_BA 0.958157542216587\"\n[1] \"2 PSME_BA 0.989054046339468\"\n[1] \"3 LAOC_BA 0.879657866994033\"\n[1] \"4 PICO_BA 0.999999999433154\"\n[1] \"5 ABGR_BA 0.94287519746020\"\n[1] \"6 PIMO_BA 0.95189763962869\"\n[1] \"7 THPL_BA 0.966678156629382\"\n[1] \"8 TSHE_BA 0.883507012327542\"\n[1] \"9 PIEN_BA 0.824698432413183\"\n[1] \"10 ABLA_BA 0.983539264208896\"\n[1] \"11 TSME_BA 0.999999999999962\"\n[1] \"12 PIPO_TD 0.990227059685376\"\n[1] \"13 PSME_TD 0.984574970635221\"\n[1] \"14 LAOC_TD 0.967946943578243\"\n[1] \"15 PICO_TD 0.999999999998031\"\n[1] \"16 ABGR_TD 0.885766103122609\"\n[1] \"17 PIMO_TD 0.985713925090166\"\n[1] \"18 THPL_TD 0.930608590044875\"\n[1] \"19 TSHE_TD 0.909809652532038\"\n[1] \"20 PIEN_TD 0.972878138067553\"\n[1] \"21 ABLA_TD 0.994202212976257\"\n[1] \"22 TSME_TD 0.999999999999727\"\n\n# What about MM alone?\nmap.mm = map.spp[82:165,]\nobs.mm = obs.spp[82:165,]\nfor (i in 1:22) {\n  print(paste(i, cone[i], cor(map.mm[,i], obs.mm[,i])))\n}\n[1] \"1 PIPO_BA 0.54174561861259\"\n[1] \"2 PSME_BA 0.502371706768285\"\n[1] \"3 LAOC_BA 0.336491307740372\"\n[1] \"4 PICO_BA 0.769005891422756\"\n[1] \"5 ABGR_BA 0.700255533380152\"\n[1] \"6 PIMO_BA -0.0218655430701594\"\n[1] \"7 THPL_BA 0.572185287840941\"\n[1] \"8 TSHE_BA NA\"\n[1] \"9 PIEN_BA 0.736545484513159\"\n[1] \"10 ABLA_BA NA\"\n[1] \"11 TSME_BA NA\"\n[1] \"12 PIPO_TD 0.740185593737342\"\n[1] \"13 PSME_TD 0.55703878045172\"\n[1] \"14 LAOC_TD 0.318629139940433\"\n[1] \"15 PICO_TD 0.953827411449894\"\n[1] \"16 ABGR_TD 0.611638704818559\"\n[1] \"17 PIMO_TD -0.0232372511702499\"\n[1] \"18 THPL_TD 0.547085885543925\"\n[1] \"19 TSHE_TD NA\"\n[1] \"20 PIEN_TD 0.418807084105866\"\n[1] \"21 ABLA_TD NA\"\n[1] \"22 TSME_TD NA\"\n\n# Can also look at Total BA and Total TD...\n# All plots, Total BA\ncor(map[,15], y[,18])\n[1] 0.9434244\n\n# All plots, Total TD\ncor(map[,27], y[,36])\n[1] 0.8679667\n\n# SJ, Total BA\ncor(map[1:81,15], y[1:81,18])\n[1] 0.9854037\n\n# MM, Total BA\ncor(map[82:165,15], y[82:165,18])\n[1] 0.875219\n\n# SJ, Total TD\ncor(map[1:81,27], y[1:81,36])\n[1] 0.9942984\n\n# MM, Total TD\ncor(map[82:165,27], y[82:165,36])\n[1] 0.7224604\n\n# Why better maps at the St. Joe?  Better lidar?  Larger plots?  Better plot sampling?  Wider gradients?\n\n\n# Now need to make figures in R for the paper.\nrequire(sp)\ndensity.g = read.asciigrid(\"C:/data/imputation/sj/density.asc\") [202:452,395:895]\nelev.g = read.asciigrid(\"C:/data/imputation/sj/elev.asc\") [202:452,395:895]\nh05th.g = read.asciigrid(\"C:/data/imputation/sj/h05th.asc\") [202:452,395:895]\nh25th.g = read.asciigrid(\"C:/data/imputation/sj/h25th.asc\") [202:452,395:895]\nhaad.g = read.asciigrid(\"C:/data/imputation/sj/haad.asc\") [202:452,395:895]\nhcv.g = read.asciigrid(\"C:/data/imputation/sj/hcv.asc\") [202:452,395:895]\nhrange.g = read.asciigrid(\"C:/data/imputation/sj/hrange.asc\") [202:452,395:895]\niskew.g = read.asciigrid(\"C:/data/imputation/sj/iskew.asc\") [202:452,395:895]\nivar.g = read.asciigrid(\"C:/data/imputation/sj/ivar.asc\") [202:452,395:895]\npct2.g = read.asciigrid(\"C:/data/imputation/sj/pct2.asc\") [202:452,395:895]\nstratum1.g = read.asciigrid(\"C:/data/imputation/sj/stratum1.asc\") [202:452,395:895]\ntsrai.g = read.asciigrid(\"C:/data/imputation/sj/trasp.asc\") [202:452,395:895]\n\n# Moscow Mt...\ndensity.g = read.asciigrid(\"C:/data/imputation/mm/density.asc\") [50:300,200:700]\nelev.g = read.asciigrid(\"C:/data/imputation/mm/dem30.asc\") [50:300,200:700]\nh05th.g = read.asciigrid(\"C:/data/imputation/mm/h05th.asc\") [50:300,200:700]\nh25th.g = read.asciigrid(\"C:/data/imputation/mm/h25th.asc\") [50:300,200:700]\nhaad.g = read.asciigrid(\"C:/data/imputation/mm/haad.asc\") [50:300,200:700]\nhcv.g = read.asciigrid(\"C:/data/imputation/mm/hcv.asc\") [50:300,200:700]\nhrange.g = read.asciigrid(\"C:/data/imputation/mm/hrange.asc\") [50:300,200:700]\niskew.g = read.asciigrid(\"C:/data/imputation/mm/iskew.asc\") [50:300,200:700]\nivar.g = read.asciigrid(\"C:/data/imputation/mm/ivar.asc\") [50:300,200:700]\npct2.g = read.asciigrid(\"C:/data/imputation/mm/pct2.asc\") [50:300,200:700]\nstratum1.g = read.asciigrid(\"C:/data/imputation/mm/stratum1.asc\") [50:300,200:700]\ntsrai.g = read.asciigrid(\"C:/data/imputation/mm/trasp.asc\") [50:300,200:700]\n\npar(mfcol=c(4,3), mar=c(3,0,2,0), font.main=2)\nimage(elev.g,col=gray(0:255/255))\ntitle(main=\"Elevation\")\n# points(x, col=\"red\")\nimage(haad.g,col=gray(0:255/255))\ntitle(main=\"Height Average Absolute Deviation\")\n# points(x, col=\"red\")\nimage(h25th.g,col=gray(0:255/255))\ntitle(main=\"Height 25th Percentile\")\n# points(x, col=\"red\")\nimage(density.g,col=gray(0:255/255))\ntitle(main=\"Canopy Density\")\n# points(x, col=\"red\")\nimage(tsrai.g,col=gray(0:255/255))\ntitle(main=\"Transformed Aspect\")\n# points(x, col=\"red\")\nimage(hcv.g,col=gray(0:255/255))\ntitle(main=\"Height Coefficient of Variation\")\n# points(x, col=\"red\")\nimage(ivar.g,col=gray(0:255/255))\ntitle(main=\"Intensity Variance\")\n# points(x, col=\"red\")\nimage(stratum1.g,col=gray(0:255/255))\ntitle(main=\"Canopy Stratum 1\")\n# points(x, col=\"red\")\nimage(hrange.g,col=gray(0:255/255))\ntitle(main=\"Height Range\")\n# points(x, col=\"red\")\nimage(h05th.g,col=gray(0:255/255))\ntitle(main=\"Height 5th Percentile\")\n# points(x, col=\"red\")\nimage(iskew.g,col=gray(0:255/255))\ntitle(main=\"Intensity Skewness\")\n# points(x, col=\"red\")\nimage(pct2.g,col=gray(0:255/255))\ntitle(main=\"Percentage of 2nd Returns\")\n# points(x, col=\"red\")\n\n# There are high outlying values at MM, so I will only show the St. Joe X variables in the paper figure.\n# Here's how I made a subset of the map area.\nwrite.asciigrid(elev.g, \"elevsub.asc\", na.value=-9999)\n\n# Then, in GRID:\nelevsub = asciigrid(elevsub.asc, float)\nmapgrid = con(elevsub > 0, 1)\nmappoly = gridpoly(mapgrid)\narc export cover mappoly sjmaparea\n\n\n# Image the various runs to compare YAI methods.\npipo_ba.rf2 = read.asciigrid(\"C:/data/imputation/sj/pipo_ba.asc\") [202:452,395:895]\npsme_ba.rf2 = read.asciigrid(\"C:/data/imputation/sj/psme_ba.asc\") [202:452,395:895]\nlaoc_ba.rf2 = read.asciigrid(\"C:/data/imputation/sj/laoc_ba.asc\") [202:452,395:895]\npico_ba.rf2 = read.asciigrid(\"C:/data/imputation/sj/pico_ba.asc\") [202:452,395:895]\nabgr_ba.rf2 = read.asciigrid(\"C:/data/imputation/sj/abgr_ba.asc\") [202:452,395:895]\npimo_ba.rf2 = read.asciigrid(\"C:/data/imputation/sj/pimo_ba.asc\") [202:452,395:895]\nthpl_ba.rf2 = read.asciigrid(\"C:/data/imputation/sj/thpl_ba.asc\") [202:452,395:895]\ntshe_ba.rf2 = read.asciigrid(\"C:/data/imputation/sj/tshe_ba.asc\") [202:452,395:895]\npien_ba.rf2 = read.asciigrid(\"C:/data/imputation/sj/pien_ba.asc\") [202:452,395:895]\nabla_ba.rf2 = read.asciigrid(\"C:/data/imputation/sj/abla_ba.asc\") [202:452,395:895]\ntsme_ba.rf2 = read.asciigrid(\"C:/data/imputation/sj/tsme_ba.asc\") [202:452,395:895]\ntotal_ba.rf2 = read.asciigrid(\"C:/data/imputation/sj/total_ba.asc\") [202:452,395:895]\npipo_td.rf2 = read.asciigrid(\"C:/data/imputation/sj/pipo_td.asc\") [202:452,395:895]\npsme_td.rf2 = read.asciigrid(\"C:/data/imputation/sj/psme_td.asc\") [202:452,395:895]\nlaoc_td.rf2 = read.asciigrid(\"C:/data/imputation/sj/laoc_td.asc\") [202:452,395:895]\npico_td.rf2 = read.asciigrid(\"C:/data/imputation/sj/pico_td.asc\") [202:452,395:895]\nabgr_td.rf2 = read.asciigrid(\"C:/data/imputation/sj/abgr_td.asc\") [202:452,395:895]\npimo_td.rf2 = read.asciigrid(\"C:/data/imputation/sj/pimo_td.asc\") [202:452,395:895]\nthpl_td.rf2 = read.asciigrid(\"C:/data/imputation/sj/thpl_td.asc\") [202:452,395:895]\ntshe_td.rf2 = read.asciigrid(\"C:/data/imputation/sj/tshe_td.asc\") [202:452,395:895]\npien_td.rf2 = read.asciigrid(\"C:/data/imputation/sj/pien_td.asc\") [202:452,395:895]\nabla_td.rf2 = read.asciigrid(\"C:/data/imputation/sj/abla_td.asc\") [202:452,395:895]\ntsme_td.rf2 = read.asciigrid(\"C:/data/imputation/sj/tsme_td.asc\") [202:452,395:895]\ntotal_td.rf2 = read.asciigrid(\"C:/data/imputation/sj/total_td.asc\") [202:452,395:895]\n\n# Moscow Mt...\npipo_ba.rf2 = read.asciigrid(\"C:/data/imputation/mm/pipo_ba.asc\") [50:300,200:700]\npsme_ba.rf2 = read.asciigrid(\"C:/data/imputation/mm/psme_ba.asc\") [50:300,200:700]\nlaoc_ba.rf2 = read.asciigrid(\"C:/data/imputation/mm/laoc_ba.asc\") [50:300,200:700]\npico_ba.rf2 = read.asciigrid(\"C:/data/imputation/mm/pico_ba.asc\") [50:300,200:700]\nabgr_ba.rf2 = read.asciigrid(\"C:/data/imputation/mm/abgr_ba.asc\") [50:300,200:700]\npimo_ba.rf2 = read.asciigrid(\"C:/data/imputation/mm/pimo_ba.asc\") [50:300,200:700]\nthpl_ba.rf2 = read.asciigrid(\"C:/data/imputation/mm/thpl_ba.asc\") [50:300,200:700]\ntshe_ba.rf2 = read.asciigrid(\"C:/data/imputation/mm/tshe_ba.asc\") [50:300,200:700]\npien_ba.rf2 = read.asciigrid(\"C:/data/imputation/mm/pien_ba.asc\") [50:300,200:700]\nabla_ba.rf2 = read.asciigrid(\"C:/data/imputation/mm/abla_ba.asc\") [50:300,200:700]\ntsme_ba.rf2 = read.asciigrid(\"C:/data/imputation/mm/tsme_ba.asc\") [50:300,200:700]\ntotal_ba.rf2 = read.asciigrid(\"C:/data/imputation/mm/total_ba.asc\") [50:300,200:700]\npipo_td.rf2 = read.asciigrid(\"C:/data/imputation/mm/pipo_td.asc\") [50:300,200:700]\npsme_td.rf2 = read.asciigrid(\"C:/data/imputation/mm/psme_td.asc\") [50:300,200:700]\nlaoc_td.rf2 = read.asciigrid(\"C:/data/imputation/mm/laoc_td.asc\") [50:300,200:700]\npico_td.rf2 = read.asciigrid(\"C:/data/imputation/mm/pico_td.asc\") [50:300,200:700]\nabgr_td.rf2 = read.asciigrid(\"C:/data/imputation/mm/abgr_td.asc\") [50:300,200:700]\npimo_td.rf2 = read.asciigrid(\"C:/data/imputation/mm/pimo_td.asc\") [50:300,200:700]\nthpl_td.rf2 = read.asciigrid(\"C:/data/imputation/mm/thpl_td.asc\") [50:300,200:700]\ntshe_td.rf2 = read.asciigrid(\"C:/data/imputation/mm/tshe_td.asc\") [50:300,200:700]\npien_td.rf2 = read.asciigrid(\"C:/data/imputation/mm/pien_td.asc\") [50:300,200:700]\nabla_td.rf2 = read.asciigrid(\"C:/data/imputation/mm/abla_td.asc\") [50:300,200:700]\ntsme_td.rf2 = read.asciigrid(\"C:/data/imputation/mm/tsme_td.asc\") [50:300,200:700]\ntotal_td.rf2 = read.asciigrid(\"C:/data/imputation/mm/total_td.asc\") [50:300,200:700]\n\npar(mfcol=c(4,3), mar=c(3,0,2,0), font.main=4)\nimage(pipo_ba.rf2,col=gray(255:0/255))\ntitle(\"Pinus ponderosa\")\n# points(x, col=\"red\")\nimage(pico_ba.rf2,col=gray(255:0/255))\ntitle(\"Pinus contorta\")\n# points(x, col=\"red\")\nimage(thpl_ba.rf2,col=gray(255:0/255))\ntitle(\"Thuja plicata\")\n# points(x, col=\"red\")\nimage(abla_ba.rf2,col=gray(255:0/255))\ntitle(\"Abies lasiocarpa\")\n# points(x, col=\"red\")\nimage(psme_ba.rf2,col=gray(255:0/255))\ntitle(\"Pseudotsuga menziesii\")\n# points(x, col=\"red\")\nimage(abgr_ba.rf2,col=gray(255:0/255))\ntitle(\"Abies grandis\")\n# points(x, col=\"red\")\nimage(tshe_ba.rf2,col=gray(255:0/255))\ntitle(\"Tsuga heterophylla\")\n# points(x, col=\"red\")\nimage(tsme_ba.rf2,col=gray(255:0/255))\ntitle(\"Tsuga mertensiana\")\n# points(x, col=\"red\")\nimage(laoc_ba.rf2,col=gray(255:0/255))\ntitle(\"Larix occidentalis\")\n# points(x, col=\"red\")\nimage(pimo_ba.rf2,col=gray(255:0/255))\ntitle(\"Pinus monticola\")\n# points(x, col=\"red\")\nimage(pien_ba.rf2,col=gray(255:0/255))\ntitle(\"Picea engelmannii\")\n# points(x, col=\"red\")\nimage(total_ba.rf2,col=gray(255:0/255))\npar(font.main=2)\ntitle(\"All Species\")\n# points(x, col=\"red\")\n\npar(mfcol=c(4,3), mar=c(3,0,2,0), font.main=4)\nimage(pipo_td.rf2,col=gray(255:0/255))\ntitle(\"Pinus ponderosa\")\n# points(x, col=\"red\")\nimage(pico_td.rf2,col=gray(255:0/255))\ntitle(\"Pinus contorta\")\n# points(x, col=\"red\")\nimage(thpl_td.rf2,col=gray(255:0/255))\ntitle(\"Thuja plicata\")\n# points(x, col=\"red\")\nimage(abla_td.rf2,col=gray(255:0/255))\ntitle(\"Abies lasiocarpa\")\n# points(x, col=\"red\")\nimage(psme_td.rf2,col=gray(255:0/255))\ntitle(\"Pseudotsuga menziesii\")\n# points(x, col=\"red\")\nimage(abgr_td.rf2,col=gray(255:0/255))\ntitle(\"Abies grandis\")\n# points(x, col=\"red\")\nimage(tshe_td.rf2,col=gray(255:0/255))\ntitle(\"Tsuga heterophylla\")\n# points(x, col=\"red\")\nimage(tsme_td.rf2,col=gray(255:0/255))\ntitle(\"Tsuga mertensiana\")\n# points(x, col=\"red\")\nimage(laoc_td.rf2,col=gray(255:0/255))\ntitle(\"Larix occidentalis\")\n# points(x, col=\"red\")\nimage(pimo_td.rf2,col=gray(255:0/255))\ntitle(\"Pinus monticola\")\n# points(x, col=\"red\")\nimage(pien_td.rf2,col=gray(255:0/255))\ntitle(\"Picea engelmannii\")\n# points(x, col=\"red\")\nimage(total_td.rf2,col=gray(255:0/255))\npar(font.main=2)\ntitle(\"All Species\")\n# points(x, col=\"red\")\n\n# There are misclassified wet species on Moscow Mt., especially western hemlock, subalpine fir to a\n# lesser extent, and only a few mountain hemlock.  I'll only map the results for St. Joe.\n\n\n########################\n# Alternative diagostics which I didn't use because the stepwise procedure on the WMAX\n# results, which had the lowest RMSD, seemed like the best approach for selecting x variables.\n\n# Prune x variables in a simulated stepwise procedure, based on MOST yai object.\nsink(\"xvars.most.txt\")\npred = x\nfor (i in 2:length(pred)) {\n  rf.most = yai(x=pred, y=y[,most], method=\"randomForest\", k=k, ann=F, ntree=300*length(most))\n  yaVarImp(rf.most, nTop=length(pred))\n  v1 = importance(rf.most$ranForest[[1]])[,\"MeanDecreaseGini\"]\n  v2 = importance(rf.most$ranForest[[2]])[,\"MeanDecreaseGini\"]\n  v3 = importance(rf.most$ranForest[[3]])[,\"MeanDecreaseGini\"]\n  v4 = importance(rf.most$ranForest[[4]])[,\"MeanDecreaseGini\"]\n  v5 = importance(rf.most$ranForest[[5]])[,\"MeanDecreaseGini\"]\n  v6 = importance(rf.most$ranForest[[6]])[,\"MeanDecreaseGini\"]\n  v7 = importance(rf.most$ranForest[[7]])[,\"MeanDecreaseGini\"]\n  v8 = importance(rf.most$ranForest[[8]])[,\"MeanDecreaseGini\"]\n  vmean = (v1+v2+v3+v4+v5+v6+v7+v8)/length(most)\n  vsort = sort(vmean, decreasing=T)\n  rf.most.rmsd = rmsd.yai(impute.yai(rf.most,newdata=y[,cone],method=\"closest\",observed=TRUE),scale=T)\n  keep = names(vsort[1:length(vsort)-1])\n  cat(length(pred),names(vsort[1:length(vsort)]), \"\\n\")\n  cat(length(pred),mean(rf.most.rmsd), \"\\n\")\n  pred = x[,keep]\n}\nsink()\n\n# Prune x variables in a simulated stepwise procedure, based on CONE yai object for BA.\nsink(\"xvars.cone.ba.txt\")\npred = x\nfor (i in 2:length(pred)) {\n  rf.cone.ba = yai(x=pred, y=y[,cone.ba], method=\"randomForest\", k=k, ann=F, ntree=300*length(cone.ba))\n  yaVarImp(rf.cone.ba, nTop=length(pred))\n  v1 = importance(rf.cone.ba$ranForest[[1]])[,\"MeanDecreaseGini\"]\n  v2 = importance(rf.cone.ba$ranForest[[2]])[,\"MeanDecreaseGini\"]\n  v3 = importance(rf.cone.ba$ranForest[[3]])[,\"MeanDecreaseGini\"]\n  v4 = importance(rf.cone.ba$ranForest[[4]])[,\"MeanDecreaseGini\"]\n  v5 = importance(rf.cone.ba$ranForest[[5]])[,\"MeanDecreaseGini\"]\n  v6 = importance(rf.cone.ba$ranForest[[6]])[,\"MeanDecreaseGini\"]\n  v7 = importance(rf.cone.ba$ranForest[[7]])[,\"MeanDecreaseGini\"]\n  v8 = importance(rf.cone.ba$ranForest[[8]])[,\"MeanDecreaseGini\"]\n  v9 = importance(rf.cone.ba$ranForest[[9]])[,\"MeanDecreaseGini\"]\n  v10 = importance(rf.cone.ba$ranForest[[10]])[,\"MeanDecreaseGini\"]\n  v11 = importance(rf.cone.ba$ranForest[[11]])[,\"MeanDecreaseGini\"]\n  vmean = (v1+v2+v3+v4+v5+v6+v7+v8+v9+v10+v11)/length(cone.ba)\n  vsort = sort(vmean, decreasing=T)\n  rf.cone.ba.rmsd = rmsd.yai(impute.yai(rf.cone.ba,newdata=y[,cone.ba],method=\"closest\",observed=TRUE),scale=T)\n  keep = names(vsort[1:length(vsort)-1])\n  cat(length(pred),names(vsort[1:length(vsort)]), \"\\n\")\n  cat(length(pred),mean(rf.cone.ba.rmsd), \"\\n\")\n  pred = x[,keep]\n}\nsink()\n\n# Prune x variables in a simulated stepwise procedure, based on CONE yai object for TD.\nsink(\"xvars.cone.td.txt\")\npred = x\nfor (i in 2:length(pred)) {\n  rf.cone.td = yai(x=pred, y=y[,cone.td], method=\"randomForest\", k=k, ann=F, ntree=300*length(cone.td))\n  yaVarImp(rf.cone.td, nTop=length(pred))\n  v1 = importance(rf.cone.td$ranForest[[1]])[,\"MeanDecreaseGini\"]\n  v2 = importance(rf.cone.td$ranForest[[2]])[,\"MeanDecreaseGini\"]\n  v3 = importance(rf.cone.td$ranForest[[3]])[,\"MeanDecreaseGini\"]\n  v4 = importance(rf.cone.td$ranForest[[4]])[,\"MeanDecreaseGini\"]\n  v5 = importance(rf.cone.td$ranForest[[5]])[,\"MeanDecreaseGini\"]\n  v6 = importance(rf.cone.td$ranForest[[6]])[,\"MeanDecreaseGini\"]\n  v7 = importance(rf.cone.td$ranForest[[7]])[,\"MeanDecreaseGini\"]\n  v8 = importance(rf.cone.td$ranForest[[8]])[,\"MeanDecreaseGini\"]\n  v9 = importance(rf.cone.td$ranForest[[9]])[,\"MeanDecreaseGini\"]\n  v10 = importance(rf.cone.td$ranForest[[10]])[,\"MeanDecreaseGini\"]\n  v11 = importance(rf.cone.td$ranForest[[11]])[,\"MeanDecreaseGini\"]\n  vmean = (v1+v2+v3+v4+v5+v6+v7+v8+v9+v10+v11)/length(cone.td)\n  vsort = sort(vmean, decreasing=T)\n  rf.cone.td.rmsd = rmsd.yai(impute.yai(rf.cone.td,newdata=y[,cone.td],method=\"closest\",observed=TRUE),scale=T)\n  keep = names(vsort[1:length(vsort)-1])\n  cat(length(pred),names(vsort[1:length(vsort)]), \"\\n\")\n  cat(length(pred),mean(rf.cone.td.rmsd), \"\\n\")\n  pred = x[,keep]\n}\nsink()\n\n# Prune x variables in a simulated stepwise procedure, based on ALL yai object for BA.\nsink(\"xvars.all.ba.txt\")\npred = x\nfor (i in 2:length(pred)) {\n  rf.all.ba = yai(x=pred, y=y[,all.ba], method=\"randomForest\", k=k, ann=F, ntree=300*length(all.ba))\n  yaVarImp(rf.all.ba, nTop=length(pred))\n  v1 = importance(rf.all.ba$ranForest[[1]])[,\"MeanDecreaseGini\"]\n  v2 = importance(rf.all.ba$ranForest[[2]])[,\"MeanDecreaseGini\"]\n  v3 = importance(rf.all.ba$ranForest[[3]])[,\"MeanDecreaseGini\"]\n  v4 = importance(rf.all.ba$ranForest[[4]])[,\"MeanDecreaseGini\"]\n  v5 = importance(rf.all.ba$ranForest[[5]])[,\"MeanDecreaseGini\"]\n  v6 = importance(rf.all.ba$ranForest[[6]])[,\"MeanDecreaseGini\"]\n  v7 = importance(rf.all.ba$ranForest[[7]])[,\"MeanDecreaseGini\"]\n  v8 = importance(rf.all.ba$ranForest[[8]])[,\"MeanDecreaseGini\"]\n  v9 = importance(rf.all.ba$ranForest[[9]])[,\"MeanDecreaseGini\"]\n  v10 = importance(rf.all.ba$ranForest[[10]])[,\"MeanDecreaseGini\"]\n  v11 = importance(rf.all.ba$ranForest[[11]])[,\"MeanDecreaseGini\"]\n  v12 = importance(rf.all.ba$ranForest[[12]])[,\"MeanDecreaseGini\"]\n  v13 = importance(rf.all.ba$ranForest[[13]])[,\"MeanDecreaseGini\"]\n  v14 = importance(rf.all.ba$ranForest[[14]])[,\"MeanDecreaseGini\"]\n  v15 = importance(rf.all.ba$ranForest[[15]])[,\"MeanDecreaseGini\"]\n  v16 = importance(rf.all.ba$ranForest[[16]])[,\"MeanDecreaseGini\"]\n  v17 = importance(rf.all.ba$ranForest[[17]])[,\"MeanDecreaseGini\"]\n  v18 = importance(rf.all.ba$ranForest[[18]])[,\"MeanDecreaseGini\"]\n  vmean = (v1+v2+v3+v4+v5+v6+v7+v8+v9+v10+v11+v12+v13+v14+v15+v16+v17+v18)/length(all.ba)\n  vsort = sort(vmean, decreasing=T)\n  rf.all.ba.rmsd = rmsd.yai(impute.yai(rf.all.ba,newdata=y,method=\"closest\",observed=TRUE),scale=T)\n  keep = names(vsort[1:length(vsort)-1])\n  cat(length(pred),names(vsort[1:length(vsort)]), \"\\n\")\n  cat(length(pred),mean(rf.all.ba.rmsd), \"\\n\")\n  pred = x[,keep]\n}\nsink()\n\n# Prune x variables in a simulated stepwise procedure, based on ALL yai object for TD.\nsink(\"xvars.all.td.txt\")\npred = x\nfor (i in 2:length(pred)) {\n  rf.all.td = yai(x=pred, y=y[,all.td], method=\"randomForest\", k=k, ann=F, ntree=300*length(all.td))\n  yaVarImp(rf.all.td, nTop=length(pred))\n  v1 = importance(rf.all.td$ranForest[[1]])[,\"MeanDecreaseGini\"]\n  v2 = importance(rf.all.td$ranForest[[2]])[,\"MeanDecreaseGini\"]\n  v3 = importance(rf.all.td$ranForest[[3]])[,\"MeanDecreaseGini\"]\n  v4 = importance(rf.all.td$ranForest[[4]])[,\"MeanDecreaseGini\"]\n  v5 = importance(rf.all.td$ranForest[[5]])[,\"MeanDecreaseGini\"]\n  v6 = importance(rf.all.td$ranForest[[6]])[,\"MeanDecreaseGini\"]\n  v7 = importance(rf.all.td$ranForest[[7]])[,\"MeanDecreaseGini\"]\n  v8 = importance(rf.all.td$ranForest[[8]])[,\"MeanDecreaseGini\"]\n  v9 = importance(rf.all.td$ranForest[[9]])[,\"MeanDecreaseGini\"]\n  v10 = importance(rf.all.td$ranForest[[10]])[,\"MeanDecreaseGini\"]\n  v11 = importance(rf.all.td$ranForest[[11]])[,\"MeanDecreaseGini\"]\n  v12 = importance(rf.all.td$ranForest[[12]])[,\"MeanDecreaseGini\"]\n  v13 = importance(rf.all.td$ranForest[[13]])[,\"MeanDecreaseGini\"]\n  v14 = importance(rf.all.td$ranForest[[14]])[,\"MeanDecreaseGini\"]\n  v15 = importance(rf.all.td$ranForest[[15]])[,\"MeanDecreaseGini\"]\n  v16 = importance(rf.all.td$ranForest[[16]])[,\"MeanDecreaseGini\"]\n  v17 = importance(rf.all.td$ranForest[[17]])[,\"MeanDecreaseGini\"]\n  v18 = importance(rf.all.td$ranForest[[18]])[,\"MeanDecreaseGini\"]\n  vmean = (v1+v2+v3+v4+v5+v6+v7+v8+v9+v10+v11+v12+v13+v14+v15+v16+v17+v18)/length(all.td)\n  vsort = sort(vmean, decreasing=T)\n  rf.all.td.rmsd = rmsd.yai(impute.yai(rf.all.td,newdata=y,method=\"closest\",observed=TRUE),scale=T)\n  keep = names(vsort[1:length(vsort)-1])\n  cat(length(pred),names(vsort[1:length(vsort)]), \"\\n\")\n  cat(length(pred),mean(rf.all.td.rmsd), \"\\n\")\n  pred = x[,keep]\n}\nsink()\n\n\n# Choose best 25 x variables and rerun\nxsub = names(sort(importance(rf$ranForest$Total_TD)[,\"MeanDecreaseGini\"], decreasing=T))\nkeep = xsub[1:25]\npred = x[,keep]\neuc=yai(x=pred, y=y, method=\"euclidean\", k=k, ann=F)\ngnn=yai(x=pred, y=y, method=\"gnn\", k=k, ann=F)\nmal=yai(x=pred, y=y, method=\"mahalanobis\", k=k, ann=F)\nmsn=yai(x=pred, y=y, method=\"msn\", k=k, ann=F)\nmsn2=yai(x=pred, y=y, method=\"msn2\", k=k, ann=F)\nrf=yai(x=pred, y=y, method=\"randomForest\", k=k, ann=F)\nrf2=yai(x=pred,y=rfy,method=\"randomForest\",k=k, ann=F)\n\n# Choose best 20 x variables and rerun\nxsub = names(sort(importance(rf$ranForest$Total_TD)[,\"MeanDecreaseGini\"], decreasing=T))\nkeep = xsub[1:20]\npred = x[,keep]\neuc=yai(x=pred, y=y, method=\"euclidean\", k=k, ann=F)\ngnn=yai(x=pred, y=y, method=\"gnn\", k=k, ann=F)\nmal=yai(x=pred, y=y, method=\"mahalanobis\", k=k, ann=F)\nmsn=yai(x=pred, y=y, method=\"msn\", k=k, ann=F)\nmsn2=yai(x=pred, y=y, method=\"msn2\", k=k, ann=F)\nrf=yai(x=pred, y=y, method=\"randomForest\", k=k, ann=F)\nrf2=yai(x=pred,y=rfy,method=\"randomForest\",k=k, ann=F)\n\n# Choose best 15 x variables and rerun\nxsub = names(sort(importance(rf$ranForest$Total_TD)[,\"MeanDecreaseGini\"], decreasing=T))\nkeep = xsub[1:15]\npred = x[,keep]\neuc=yai(x=pred, y=y, method=\"euclidean\", k=k, ann=F)\ngnn=yai(x=pred, y=y, method=\"gnn\", k=k, ann=F)\nmal=yai(x=pred, y=y, method=\"mahalanobis\", k=k, ann=F)\nmsn=yai(x=pred, y=y, method=\"msn\", k=k, ann=F)\nmsn2=yai(x=pred, y=y, method=\"msn2\", k=k, ann=F)\nrf=yai(x=pred, y=y, method=\"randomForest\", k=k, ann=F)\nrf2=yai(x=pred,y=rfy,method=\"randomForest\",k=k, ann=F)\n\n# Choose best 10 x variables and rerun\nxsub = names(sort(importance(rf$ranForest$Total_TD)[,\"MeanDecreaseGini\"], decreasing=T))\nkeep = xsub[1:10]\npred = x[,keep]\neuc=yai(x=pred, y=y, method=\"euclidean\", k=k, ann=F)\ngnn=yai(x=pred, y=y, method=\"gnn\", k=k, ann=F)\nmal=yai(x=pred, y=y, method=\"mahalanobis\", k=k, ann=F)\nmsn=yai(x=pred, y=y, method=\"msn\", k=k, ann=F)\nmsn2=yai(x=pred, y=y, method=\"msn2\", k=k, ann=F)\nrf=yai(x=pred, y=y, method=\"randomForest\", k=k, ann=F)\nrf2=yai(x=pred,y=rfy,method=\"randomForest\",k=k, ann=F)\n",
    "created" : 1419878044631.000,
    "dirty" : true,
    "encoding" : "",
    "folds" : "",
    "hash" : "1153998190",
    "id" : "9E931525",
    "lastKnownWriteTime" : 29555198979604527,
    "path" : null,
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled22"
    },
    "source_on_save" : false,
    "type" : "r_source"
}